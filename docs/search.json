[
  {
    "objectID": "timeseries_1.html",
    "href": "timeseries_1.html",
    "title": "4  시계열분석",
    "section": "",
    "text": "4.1 introduction\n시계열적 자료를 분석하고 나타나는 현상과 특정 요인과 관련성을 탐색해보는 시간입니다. 예를 들어 미세먼지가 높은 날 심혈관 질환이 발생하는가?에 대한 질문에 답하기 위해서 생가할 것이 몇가지 있습니다. 미세먼지가 높은 날이란? 심혈관 질환 사망이 높은 날이란? 이 두가지 요소를 검토하게 됩니다.  그런데 심혈관 질환의 사망은 요일마다 다르고, 계절에 따라 변동하며, 장기 적으로는 점차 증가 또는 감소를 합니다. 그런데 미세먼지도 점차 증가하고 있으니, 단순 상관관계를 보면 미세먼지도 증가 심혈관 사망도 증가하면 양의 관련성을 보이게 됩니다. 마찬가지로 GDP와 자살의 관계를 보면 어떨까요? 우리나라의 자살률은 증가하고 있습니다. 그런데 GDP도 증가하고 있습니다. 그러니 GDP의 증가와 자살의 증가는 양의 상관관계가 있다고 나옵니다. 맞나요? 네 심혈관 사망, 자살의 증가의 계절적 요소, 장기간 추세(trend)가 아니라 변동이 미세먼지나 GDP의 변동과 어떠한 관계가 있는지가 우리의 궁금증일 것 입니다. 이러한 궁금증을 R을 이용해서 풀어보도록 하겠습니다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>시계열분석</span>"
    ]
  },
  {
    "objectID": "timeseries_1.html#공기-오염와-건강",
    "href": "timeseries_1.html#공기-오염와-건강",
    "title": "4  시계열분석",
    "section": "4.2 공기 오염와 건강",
    "text": "4.2 공기 오염와 건강\nthe original book is https://www.springer.com/gp/book/9780387781662 이 책에서 중요한 부분을 요약하고, 몇몇을 추가하여 진행하겠습니다. 원본을 읽어 보시는 것을 추천해 드립니다.\n\n4.2.1 시작\n이 책은 NMMAPSlite 패키지를 사용했지만, 해당 패키지와 데이터는 사용하기 쉽지 않습니다. 따라서 Gasparrini의 dlnm 패키지와 해당 패키지의 데이터가 이 요약 튜토리얼(https://github.com/gasparrini/dlnm/tree/master/data)에서 사용되었습니다.\n필요한 라이브러리를 불러옵니다.\n\nif(!require(tidyverse)) install.packages(\"tidyverse\")\nif(!require(dlnm)) install.packages(\"dlnm\")\nif(!require(ggplot2)) install.packages(\"ggplot2\")\nif(!require(readxl)) install.packages(\"readxl\")\nif(!require(lubridate)) install.packages(\"lubridate\")\nif(!require(plotly)) install.packages(\"plotly\")\nif(!require(forecast)) install.packages(\"forecast\")\nif(!require(gsheet)) install.packages(\"gsheet\")\nif(!require(Hmisc)) install.packages(\"Hmisc\")\nif(!require(mgcv)) install.packages(\"mgcv\")\n\n\n\n4.2.2 환경오염과 건강을 어떻게 연구할 것인가가\n\n4.2.2.1 tell a story\n’매일 발생하는 대기 오염 수준의 변화와 매일 발생하는 사망자 수 변화 사이의 관계’에 대한 이야기를 하고 싶습니다. 따라서, 예측보다는 연관성을 추정하는 데 유용한 통계 모델이 필요합니다.\n\n\n4.2.2.2 추정 vs. 예측\n과학적으로 흥미로운 질문 중 하나는 “PM10 시계열의 변화가 사망률 시계열의 변화와 관련이 있는가?”입니다. 이 질문은 본질적으로 시간에 따라 변하는 건강 결과 \\(y_{t}\\)와 시간에 따라 변하는 노출 \\(x_{t}\\) 간의 관계를 탐구합니다. 이를 간단한 선형 모델로 표현하면 (식 1.1)과 같이 나타낼 수 있습니다.\n\\[Y_{i}=\\beta_{0}+\\beta_{1}\\textrm{x}_{t}+\\epsilon_{t} \\tag{1.1}\\]\n\n\n\n\n\n\n\nestimates\ncontents\n\n\n\n\n\\(\\beta_{0}\\)\nthe mean mortality count\n\n\n\\(\\beta_{1}\\)\ntthe increase in mortality associated with a unit increase in PM10(\\(x_{t}\\))\n\n\n\\(\\epsilon_{t}\\)\na stationary mean zero error process.\n\n\n\n\\(\\bar{x}_{t}^{Y}\\): Y라는 특정 변수의 t 시점에서의 평균값을 의미합니다. \\(\\bar{x}_{t}\\): t 시점에서의 Y 변수의 실제 값을 의미합니다.\n예를 들어, 노출 시계열 \\(x_{t}\\)를 가져와서 두 부분으로 분해한다고 가정해 봅시다: 평균(\\(\\bar{x}{t}^{Y}\\)) + 편차(\\(x{t} - \\bar{x}_{t}^{Y}\\))\naverage: \\(\\bar{x}_{t}^{Y}\\)\ndeviation: \\(x_{t} - \\bar{x}_{t}^{Y}\\)\n따라서 우리는 (1.1)을 아래와 같이 재구성할 수 있습니다:\n\\[Y_{t}=\\beta_{0}+\n\\beta_{1}\\bar{x}_{t}^{Y}+\\beta_{2}(x_{t} - \\bar{x}_{t}^{Y})\n+\\epsilon_{t} \\tag{1.2}\\]\n모델 (1.2)는 \\(\\beta_1 = \\beta_2\\)라면 모델 (1.1)과 동일하지만, 모델 (1.2)는 이 둘이 같을 필요는 없습니다.\n같은 맥락에서, 연간 평균은 계절 평균 또는 월간 평균(\\(z_{t}\\))으로 분해될 수 있습니다.\n\\[z_{t} = \\bar{z}_{t}^{S}+(z_{t} - \\bar{z}_{t}^{S}) \\tag{1.3}\\] So, we can use following model\n\\[Y_{t}=\\beta_{0}+\n\\beta_{1}\\bar{x}_{t}^{Y}+\\beta_{2}\\bar{z}_{t}^{S}+\\beta_{3}(z_{t} - \\bar{z}_{t}^{S})\n+\\epsilon_{t} \\tag{1.2}\\]\n한 단계 더 나아가, 주간 이동 평균(\\(u_{t}\\))을 추가하거나 분해할 수 있습니다: \\[u_{t} = \\bar{u}_{t}^{W}+(u_{t} - \\bar{u}_{t}^{W}) \\tag{1.4}\\]\n잔차 변동(\\(r_{t}\\))을 \\(r_{t} = (u_{t} - \\bar{u}_{t}^{W})\\)로 정의하면, 확장된 모델은 이제 다음과 같습니다:\n\\[Y_{t}=\\beta_{0}+\n\\beta_{1}\\bar{x}_{t}^{Y}+\\beta_{2}\\bar{z}_{t}^{S}+\\beta_{3}\\bar{u}_{t}^W +\\beta_{4}r_{t}\n+\\epsilon_{t} \\tag{1.5}\\]\n매개변수 \\(\\beta_{4}\\)는 \\(Y_{t}\\)와 \\(x_{t}\\)의 주간 이하 변동 사이의 연관성을 설명합니다 (연간, 계절, 주간 변동을 조정한 후).\n\n질문 및 토론: \\(\\beta_{4}\\)의 의미는 무엇인가요?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>시계열분석</span>"
    ]
  },
  {
    "objectID": "timeseries_1.html#pm10과-심혈관-질환-사망률에-대한-시뮬레이션-연구",
    "href": "timeseries_1.html#pm10과-심혈관-질환-사망률에-대한-시뮬레이션-연구",
    "title": "4  시계열분석",
    "section": "4.3 PM10과 심혈관 질환 사망률에 대한 시뮬레이션 연구",
    "text": "4.3 PM10과 심혈관 질환 사망률에 대한 시뮬레이션 연구\n먼저, 시뮬레이션 데이터를 사용하여 시계열 데이터 분석을 이해해보겠습니다.\n\nx를 날짜로 생각하고, 가상으로 300일 동안 랜덤 변수 y1과 PM10(미세먼지)을 4.5배 곱한 값을 생성해봅시다.\n\n\nset.seed(1)\nx  &lt;- 1:300\ny1 &lt;- 5*rnorm(300, sd=.1)+15\npm &lt;- y1*4.5\nplot(x, pm, type='l')\n\n\n\n\n\n\n\n\n\n여기서는 장기적인 추세가 점진적으로 증가한다고 가정하고, sin() 함수를 통해 계절적 요인을 추가했으며, 이를 0.03으로 곱했습니다.\n\n\ny2 &lt;- y1*5+ sin(x/2)*5+ x * 0.03 \ny2[y2&lt; 0]&lt;-0\ny3&lt;-round(y2)\nplot(y3, type='l')\n\n\n\n\n\n\n\n\n\n지연 효과와 특정 이벤트가 있는 날을 추가해봤습니다. 그리고 데이터프레임을 만들었습니다\n\n\nlag &lt;-6\nmean(y3)\n\n[1] 79.58667\n\ndeath &lt;- c(rep(c(80,79,81), (lag/3)), y3[1:(length(y3)-lag)])  \nevent &lt;- c(rep(1, 30), rep(1, 30), rep(0, 240)) \neventd &lt;- c(rep(40,30), rep(30, 30), rep(0, 240))\ndeath2&lt;-death+eventd+10\ngg &lt;- data.frame(x, pm, y3, death, event, death2) \nhead(gg)\n\n  x       pm y3 death event death2\n1 1 66.09048 76    80     1    130\n2 2 67.91320 80    79     1    129\n3 3 65.61984 78    81     1    131\n4 4 71.08938 84    80     1    130\n5 5 68.24139 79    79     1    129\n6 6 65.65395 74    81     1    131\n\n\n\n이제 그래프를 그려봅시다. 처음 50일 동안 이벤트가 있어서 심혈관 사망률이 높습니다. 그 후 심혈관 질환 사망률은 계절적 요소와 함께 천천히 증가합니다. 미세먼지는 랜덤 + 계절적 요소로 생성되었습니다.\n\n\nplot(x, pm, type=\"l\", col=grey(0.5), ylim=c(50, 140), xlim=c(0, 300))\ngrid()\nlines(x, death2, col=grey(0.7), type=\"p\", cex=0.5)\n\n\n\n\n\n\n\n\n\n이제 간단한 회귀 분석을 해봅시다. 어떤 관계를 관찰할 수 있나요? 이벤트 기간 동안 많은 사람이 사망했습니다. 하지만 PM10과 심혈관 질환 사망률 사이에는 관계가 없어 보입니다.\n\n분명히 미세먼지와 관련되도록 시뮬레이션으로 만든 심혈관 질환 사망률 데이터인데요. 왜 그럴까요? 아직 ’지연(lag)’과 ’계절성(seasonality)’이 고려되지 않았습니다\n\nmt3 &lt;- glm(death2 ~ x+sin(x/2)+pm+event)\nsummary(mt3)$coefficients\n\n               Estimate  Std. Error     t value      Pr(&gt;|t|)\n(Intercept) 90.10455149 6.861474711  13.1319513  2.476263e-31\nx            0.02379324 0.003500538   6.7970236  5.915161e-11\nsin(x/2)    -4.41585403 0.308633540 -14.3077581  1.247252e-35\npm          -0.06144597 0.101078610  -0.6079028  5.437196e-01\nevent       35.05109683 0.757861036  46.2500315 3.230388e-137\n\n\n\n그래프를 다시 보고, 적합된 선(fitted line)은 어떠한가요?\n\n\nplot(x, pm, type=\"l\", col=grey(0.5), ylim=c(50, 140), xlim=c(0, 300))\ngrid()\nlines(x, death2, col=grey(0.7), type=\"p\", cex=0.5)\nmp3 &lt;- c( predict(mt3))\nlines(x, mp3, col=75)\n\n\n\n\n\n\n\n\n\n이제 사망률 잔차와 PM10 간의 간단한 회귀 모델입니다. 이게 맞나요?\n\n\nmt2 &lt;- glm(death2 ~ x+sin(x/2)+event)\nresid_mt2 &lt;-resid(mt2)\nrisk.m0&lt;-glm(resid_mt2 ~ pm, family=gaussian)\nsummary(risk.m0)\n\n\nCall:\nglm(formula = resid_mt2 ~ pm, family = gaussian)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  4.14114    6.79037    0.61    0.542\npm          -0.06128    0.10043   -0.61    0.542\n\n(Dispersion parameter for gaussian family taken to be 14.18007)\n\n    Null deviance: 4230.9  on 299  degrees of freedom\nResidual deviance: 4225.7  on 298  degrees of freedom\nAIC: 1650.9\n\nNumber of Fisher Scoring iterations: 2\n\nrisk.mp0 &lt;- c( predict(risk.m0))\nplot(pm, resid_mt2, type='p', cex=0.5)\nlines(pm, (risk.mp0), col=25)\n\n\n\n\n\n\n\n\n\n여기 또 다른 사망률 잔차와 PM10 잔차 간의 간단한 회귀 모델이 있습니다. 이게 맞나요?\n\n\nmt2 &lt;- glm(death2 ~ x+sin(x/2)+event)\nresid_mt2 &lt;-resid(mt2)\npm2 &lt;- glm(pm ~ x+sin(x/2))\nresid_pm2 &lt;-resid(pm2)\n\nrisk.m1&lt;-glm(resid_mt2 ~ resid_pm2, family=gaussian)\nrisk.mp1 &lt;- c( predict(risk.m1))\nplot(resid_pm2, resid_mt2, type='p', cex=0.5)\nlines(resid_pm2, (risk.mp0), col=25)\n\n\n\n\n\n\n\n\n이것은 직관적인 그래프입니다. 시간 추세와 계절적 변동을 제거한 후 두 잔차 간의 관계를 보여줍니다.\n\n4.3.0.1 자기상관 (Autocorrelation)\n\nlibrary(tidyverse)\ndat = cbind('time'=x, pm,death2,event) %&gt;% data.frame() %&gt;% tibble()\ndat %&gt;% head()\n\n# A tibble: 6 × 4\n   time    pm death2 event\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1     1  66.1    130     1\n2     2  67.9    129     1\n3     3  65.6    131     1\n4     4  71.1    130     1\n5     5  68.2    129     1\n6     6  65.7    131     1\n\n\n자기상관(Autocorrelation)은 특정 시점의 관측값이 시간 지연(time lag)을 가진 다른 관측값과 얼마나 연관되어 있는지를 나타냅니다. 예를 들어, 주말은 7일의 자기상관을 가지며, 계절은 12개월의 자기상관을 가집니다.\n\\[ r(k) = \\frac{1}{N} \\sum_{t=1}^{N-k}\n(x_{t} - \\bar{x})(x_{t+k} - \\bar{x})/c(0) \\tag{2.1}  \\]\n\\[ c(0) = \\frac{1}{N} \\sum_{t=1}^{N-k}(x_{t} - \\bar{x})^2 \\]\n여기서:\n\n\\({r}(k)\\): 시간 지연 k에서의 자기상관계수\nN: 전체 관측값의 개수\n\\({x}_{t}\\): 시점 t에서의 관측값\n\\(\\bar{x}\\): 관측값의 평균\n\\(c(0)\\): 분산\n\n자기상관 분석에서 가장 중요한 요소 중 하나는 계절성(seasonal factor)입니다. 따라서 계절성 요인을 제거하기 전과 후의 자기상관 함수(ACF) 플롯을 비교합니다.\n\n#par(mflow)\npar(mfrow=c(4, 2))\nplot(x, death2, type='p', cex=0.5)\nacf(dat$death2)\n# adjusting seasonality\nar1 &lt;- glm(death2 ~ x +sin(x/2)+event)\nplot(x, death2, type='p', cex=0.5)\nlines(x, predict(ar1), col = 'red')\nacf(resid(ar1))\n# adjusting seasonality by gam model\nlibrary(mgcv)\nar2 &lt;- mgcv::gam(death2 ~ s(x,bs=\"cc\", k=100)+event, family=gaussian)\nplot(x, death2, type='p', cex=0.5)\nlines(x, predict(ar2), col = 'red')\nacf(resid(ar2))\nlibrary(forecast)\nauto.arima(dat$death2)\n\nSeries: dat$death2 \nARIMA(2,1,2) \n\nCoefficients:\n         ar1      ar2      ma1     ma2\n      0.6952  -0.4906  -0.8632  0.7667\ns.e.  0.1099   0.1185   0.0810  0.0872\n\nsigma^2 = 15.81:  log likelihood = -835.21\nAIC=1680.42   AICc=1680.62   BIC=1698.92\n\nm1&lt;-arima(dat$death2, order=c(2,1,2))\nplot(x, death2, type='p', cex=0.5)\nlines(fitted(m1), col=\"red\")\nacf(resid(m1))\n\n\n\n\n\n\n\n\n자기상관을 제거하거나 제어하는 방법은 무엇이며, 어떤 모델이 더 적절할까요? 계절적 요인보다는 비계절적 요인의 변동에 따라 사망률이 변할 수 있다는 이야기를 하고 싶다면, 자기상관을 제어하거나 제거해야 합니다.\n‘gam’ 모델을 사용하면 쉽고 효과적입니다. 그리고 residual(death)와 residual(pm) 사이의 관계를 살펴볼 것이라는 점을 기억합시다. 자유도(df)가 100인 큐빅 스플라인(cubic spline)의 GAM 모델이 있습니다. 두 모델의 요약 결과는 거의 동일하므로, mod1의 GAM 모델을 사용하여 두 잔차 사이의 관계를 찾을 수 있습니다.\n\nlibrary(mgcv)\ntime   = dat$time\nmod1   = mgcv::gam(death2 ~ pm + s(time, bs='cc', k=100))\nmod1 %&gt;% \n  summary()\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ndeath2 ~ pm + s(time, bs = \"cc\", k = 100)\n\nParametric coefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 105.38002    6.56030  16.063   &lt;2e-16 ***\npm           -0.13082    0.09704  -1.348    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n          edf Ref.df     F p-value    \ns(time) 72.67     98 50.72  &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.943   Deviance explained = 95.7%\nGCV = 13.955  Scale est. = 10.482    n = 300\n\nrpm    = mgcv::gam(pm ~ s(time, bs='cc', k=100))\nrdeath = mgcv::gam(death2 ~ s(time, bs='cc', k=100))\nmod2   = mgcv::gam(resid(rdeath) ~ resid(rpm))\nmod2 %&gt;% \n  summary()\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nresid(rdeath) ~ resid(rpm)\n\nParametric coefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  1.528e-14  1.626e-01   0.000    1.000\nresid(rpm)  -1.036e-01  7.513e-02  -1.379    0.169\n\n\nR-sq.(adj) =  0.00301   Deviance explained = 0.634%\nGCV = 7.9884  Scale est. = 7.9352    n = 300\n\n\n지연 시간 효과(Lag time effect)는 또 다른 중요한 문제입니다. 지연 시간의 가정은 PM10 증가 시간으로부터 6일 후에 심혈관 질환 사망률이 증가한다는 것입니다.\n\nmean(pm)\n\n[1] 67.57556\n\nlag.pm&lt;-6\npm.lag &lt;- c(rep(67.5, lag.pm), pm[1:(length(pm)-lag.pm)])\nresid_mt3 &lt;-resid(mt3)\nrisk.m1&lt;-glm(resid_mt3 ~ pm.lag, family=gaussian)\nsummary(risk.m1)$coefficients\n\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) -76.437599 5.21757250 -14.65003 5.620794e-37\npm.lag        1.131554 0.07720006  14.65743 5.276143e-37\n\nrisk.mp1 &lt;- c( predict(risk.m1))\nplot(pm.lag, resid_mt3, type='p', cex=0.5)\nlines(pm.lag, risk.mp1, col=25)\n\n\n\n\n\n\n\n\nPM10과 심혈관 질환 사망률 사이에 양의 연관성이 있습니다.\n심혈관 질환과 PM10 사이의 지연 효과를 강조하는 플롯입니다.\n\nplot(x, resid_mt3, type=\"l\", col=grey(0.5), ylim=c(-15, 40), xlim=c(0, 300))\ngrid()\nlines(x, (pm-50), col=grey(0.7), type=\"l\", cex=0.5)\nlines(x, (pm.lag-60), col='red', type=\"l\", cex=0.5)\n\n\n\n\n\n\n\n\nsin()을 사용하여 계절적 요인을 고려하고 lag를 사용하여 지연 효과를 고려하고 시계열 요인(잔차)을 제거한 후 PM과 심혈관 질환 사망 사이의 관계를 분석했습니다.\n\n#install.packages('mgcv')\nlibrary(mgcv)\n#library(gam)\nmgam&lt;- mgcv::gam(death2 ~ s(x, bs=\"cc\", k=100)+event, family=gaussian)\np &lt;- predict(mgam)\nplot(x, pm, type=\"l\", col=grey(0.5), ylim=c(40, 150), xlim=c(0, 300), cex=2)\ngrid()\nlines(x, death2, col=grey(0.7), type=\"p\", cex=0.5)\nlegend(x=250, y=70, 'PM10')\nlegend(x=150, y=65, 'pm10. lag')\nlegend(x=210, y=110, 'Obs_death')\nlegend(x=10, y=50, 'Residual(Obs_Death - Gam(fitting)')\nlines(x, p)\nlines(x, (resid(mgam)+50), col='blue')\nlines(x, pm.lag-10, col='red')\n\n\n\n\n\n\n\n\n회귀 분석으로 이 문제를 해결해 봅시다. k가 더 높을 때 모델은 어떻습니까? 예, 지연 시간과 k 값을 선택하는 방법을 고려해야 합니다. 데이터 기반 방법은 적합한 모델을 선택하는 일반적인 방법입니다. 최소 AIC 또는 BIC 값은 더 적합한 모델을 제시합니다.\n\nmgam&lt;- mgcv::gam(death2 ~ s(x, bs=\"cc\", k=100)+event, family=gaussian)\np &lt;- predict(mgam)\nrisk.pp1 &lt;-glm(death2 ~ p+pm.lag,family=gaussian)\nsummary(risk.pp1)$coefficients\n\n               Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) -58.3872771 1.937186312 -30.14025 2.402418e-92\np             1.0000436 0.004566766 218.98286 0.000000e+00\npm.lag        0.8642815 0.028266084  30.57663 9.482839e-94\n\nAIC(risk.pp1)\n\n[1] 885.3135\n\n\n\nmgam150&lt;- mgcv::gam(death2 ~ s(x, bs=\"cc\", k=10)+event)\np150 &lt;- predict(mgam150)\nrisk.pp150 &lt;-glm(death2 ~ p150+ pm.lag, family=gaussian)\nsummary(risk.pp150)$coefficients\n\n               Estimate Std. Error   t value      Pr(&gt;|t|)\n(Intercept) -72.5953393 6.74682944 -10.75992  5.109224e-23\np150          0.9979243 0.01630871  61.18966 2.087420e-170\npm.lag        1.0776412 0.09754736  11.04736  5.349868e-24\n\nAIC(risk.pp1, risk.pp150)\n\n           df       AIC\nrisk.pp1    4  885.3135\nrisk.pp150  4 1629.2747\n\n\ndlnm 패키지(분산 지연 비선형 모델)를 사용하여 지연 시간을 찾아봅시다.\n\nlibrary(dlnm)\ncb1.pm &lt;-crossbasis(pm, lag=10, argvar=list(fun=\"lin\"),\n     arglag=list(fun=\"poly\", degree=3))\nmodel1 &lt;-glm(death2 ~ cb1.pm+x+event , \n              family=gaussian )\npred1.pm &lt;-crosspred(cb1.pm, model1, at=0:100, bylag=0.1, cumul=TRUE)\n\nplot(pred1.pm, \"slices\", var=1, col=3, ylab=\"RR\", ci.arg=list(density=15,lwd=2),\n     #cumul = TRUE,\nmain=\"Association with a 1-unit increase in PM10\")\n\n\n\n\n\n\n\n\n\\(\\beta\\)는 6일 지연에서 가장 높습니다.\n이제 6일을 지연 시간으로 사용하여 회귀 분석을 수행할 수 있다는 것을 알았습니다. 남은 것은 시계열 요소를 찾고, 수정하고, 이 과정을 합리화하는 방법에 대해 더 논의하는 것입니다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>시계열분석</span>"
    ]
  },
  {
    "objectID": "timeseries_1.html#사례-연구-독감과-자살",
    "href": "timeseries_1.html#사례-연구-독감과-자살",
    "title": "4  시계열분석",
    "section": "4.4 사례 연구 : 독감과 자살",
    "text": "4.4 사례 연구 : 독감과 자살\n이번에는 독감 유행과 자살에 대해 이야기해 보겠습니다. 몇 년 전 일본에서 독감 치료 중 자살이 뉴스에 나왔는데, 독감이 주로 유행하는 계절적 요인의 문제인지, 아니면 독감 유행이 정말 심할 때 자살이 발생하는 것인지 분석해 보고자 합니다.\n\n4.4.1 실습 데이터\n첫번째 실습 데이터는 감염병 포탈의 인플루엔자 자료입니다. 여기서 다운로드 합니다.\n\n\n\n인플루엔자\n\n\n두번째 실습 자료는 통계청 사망자료 입니다.\n\n\n\n인플루엔자\n\n\n이 둘을 합해 놓은 자료는 아래에 있습니다.\n이것을 data 폴더에 넣겠습니다.\n\nurl &lt;- \"https://raw.githubusercontent.com/jinhaslab/opendata/main/data/flu_suicide0.csv\"\ndownload.file(url, \"data/flu_suicide0.csv\")\n\n\nif(!require(tidyverse)) install.packages('tidyverse')\nif(!require(lubridate)) install.packages('lubridate')\nif(!require(mgcv)) install.packages('mgcv')\nif(!require(dlnm)) install.packages('dlnm')\nif(!require(gam)) install.packages('gam')\nif(!require(forecast)) install.packages('forecast')\nif(!require(Hmisc)) install.packages('Hmisc')\n\n데이터를 살펴보면 ymd 는 숫자 형식의 날짜 (기준 1970년 1월 1일), wsui 는 1주간의 자살 사망자 수, ordweek 는 주중 순위, flu 는 주중 천명당 인플루엔자 환자 수.\n\ndata0 = read_csv(\"data/flu_suicide0.csv\")\n\nNew names:\nRows: 696 Columns: 9\n── Column specification\n────────────────────────────────────────────────────────\nDelimiter: \",\" dbl (8): ...1, ymd, wsui, ordweek, nwd, YR, flu, flu2 date (1):\nymd2\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\nhead(data0)\n\n# A tibble: 6 × 9\n   ...1   ymd  wsui ordweek ymd2         nwd    YR   flu  flu2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    35 12660   238      35 2004-08-30    36  2004   0.6   0.6\n2    36 12667   211      36 2004-09-06    37  2004   2     2  \n3    37 12674   208      37 2004-09-13    38  2004   2.1   2.1\n4    38 12681   188      38 2004-09-20    39  2004   2.2   2.2\n5    39 12688   213      39 2004-09-27    40  2004   2.5   2.5\n6    40 12695   224      40 2004-10-04    41  2004   2.4   2.4\n\nplot(data0$wsui)\n\n\n\n\n\n\n\n\n신종 플루가 2009년부터 유행했고, 이후 자살자가 관련있다는 뉴스가 나오고 있으니, 2009년 전과 후를 나타내는 변수를 만들겠습니다 .\n\nmyd&lt;-data0 %&gt;% mutate(Change=ifelse(YR&gt;2008, \"from 2009\", \"before 2009\"))\n\n자료가 시계열 자료라는 것을 컴퓨터에게 알려줄 필요가 있습니다. 그리고 싸이클이 있다는 것도요. 우리는 주당 싸이클 (7일 기준)이기 때문에 frequency=365.25/7을 이용하고 시작 날짜를 정해줍니다.\n\ntsui &lt;-ts(myd$wsui, frequency=365.25/7, start = decimal_date(ymd(\"2004-08-30\")))\nlength(myd$wsui)\n\n[1] 696\n\nlength(tsui)\n\n[1] 696\n\nplot(tsui)\n\n\n\n\n\n\n\n\n여기서 시계열적 요소를 찾아 보겠습니다.\n\nd.tsui &lt;-decompose(tsui)\n#d.tsui\nplot(d.tsui) ####### find seasonal and trend\n\n\n\n\n\n\n\nsummary(d.tsui$random)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-78.1819 -18.8440  -0.3562   1.2124  18.5710 175.0412       51 \n\n\n이번에는 flu에 대한 시계열 분석을 해보겠습니다.\n\nr.tsui &lt;-d.tsui$random # residuals\ns.tsui &lt;-d.tsui$seasonal # seasonal\ntr.tsui &lt;-d.tsui$trend # long term trend\n######### influenza'\ntflu &lt;-ts(myd$flu, frequency=365.25/7, start = decimal_date(ymd(\"2004-08-30\")))\nplot(tflu)\n\n\n\n\n\n\n\n\n이것을 decomposition 하면\n\nd.tflu &lt;-decompose(tflu)\nplot(d.tflu) ####### find seasonal and trend\n\n\n\n\n\n\n\nr.tflu &lt;-d.tflu$random # residuals\ns.tflu &lt;-d.tflu$seasonal # seasonal\ntr.tflu &lt;-d.tflu$trend # long term trend\n\n\n\n4.4.2 simple time-related variable adjusting regression\n결국 resudial flu와 residual sui의 상관관계를 보면 되는 것이라고 생각해 봅시다.\n\nlibrary(Hmisc)\nplot(r.tflu, r.tsui)\nabline(lm(r.tsui ~ r.tflu))\n\n\n\n\n\n\n\nplot(Lag(r.tflu, 3), r.tsui)\nabline(lm(r.tsui ~ Lag(r.tflu, 3)))\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\npar(mar=c(4, 4, 2, 1) + 0.1)\nplot(r.tflu, r.tsui, cex=0.2, main=\"no lag model\")\nabline(lm(r.tsui ~ r.tflu))\ntext(15, 130, 'Beta =')\ntext(15, 100, 'P value=')\ntext(30, 130, round(summary(lm(r.tsui ~ Lag(r.tflu, 0)))$coefficients[c(2)], 4))\ntext(30, 100, round(summary(lm(r.tsui ~ Lag(r.tflu, 0)))$coefficients[c(8)], 4))\n\nplot(Lag(r.tflu, 3), r.tsui, cex=0.2, main=\"3 weeks lag model\")\nabline(lm(r.tsui ~ Lag(r.tflu, 3)))\ntext(15, 130, 'Beta =')\ntext(15, 100, 'P value=')\ntext(30, 130, round(summary(lm(r.tsui ~ Lag(r.tflu, 3)))$coefficients[c(2)], 3))\ntext(30, 100, round(summary(lm(r.tsui ~ Lag(r.tflu, 3)))$coefficients[c(8)], 3))\n\n\n\n\n\n\n\n\n\n\n4.4.3 ARIMA\nARIMA 및 시계열 분석 이 과정에서 다룰 수 있는 내용은 다음과 같습니다.\n\n날짜 및 시간 형식 지정\n데이터 전처리 (ts 클래스, 데이터 정리, 결측치 처리, 이상치 처리)\n시계열의 통계적 특징 (자기상관, 정상성, 계절성, 추세)\n\n\n\n\n단계\n\n\n\n\n날짜 및 시간 형식 지정\n\n\n데이터 전처리\n\n\n시계열의 통계적 특징\n\n\n표준 모델\n\n\nARIMA 모델",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>시계열분석</span>"
    ]
  },
  {
    "objectID": "timeseries_1.html#분석-및-예측-회귀-분석",
    "href": "timeseries_1.html#분석-및-예측-회귀-분석",
    "title": "4  시계열분석",
    "section": "4.5 분석 및 예측, 회귀 분석",
    "text": "4.5 분석 및 예측, 회귀 분석\n시계열 분석은 패턴을 찾기 위해 데이터를 분석하는 것이고, 예측은 그 패턴을 미래로 확장하는 것입니다. 시계열 패턴을 이용한 회귀 분석(시계열 회귀 분석)은 시계열 분석을 사용하는 회귀 방법입니다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>시계열분석</span>"
    ]
  },
  {
    "objectID": "timeseries_1.html#arima-1",
    "href": "timeseries_1.html#arima-1",
    "title": "4  시계열분석",
    "section": "4.6 ARIMA",
    "text": "4.6 ARIMA\nARIMA(자기회귀 통합 이동 평균, Autoregressive Integrated Moving Average)는 문자 그대로 자기회귀와 이동 평균을 이용합니다. 단변량 시계열(univariate time series)로 볼 수 있습니다. ARIMA 모델에서는 여러 매개변수를 자동으로 또는 수동으로 설정하여 구성합니다.\nARIMA(p, d, q)를 이해하면서 가 봅겠습니다. \n\n\n\nparameter\ncontent\nabbr\n\n\n\n\nAR\nAutoregressive part\np\n\n\nI\nIntegrateion, degree of differencing\nd\n\n\nMA\nMoving average part\nq\n\n\n\n위 에서 p, d, q를 찾아 가는 방법을 ARIMA 모델이라고 부를 수 있습니다.\n\nlags 과 forecasting errors로 구분할 수 있습니다.\n\n\n과거의 변수가 현재를 예측, autoregressive part\n\nAR(1) or ARIMA(1,0,0): first order (lag) of AR\nAR(2) or ARIMA(2,0,0): second order (lag) of AR \n\n과거의 error 가 현재를 예측 (forecasting error) = moving average part\n\nMA(1) or ARIMA(0,0,1): first order of MA\nMA(2) or ARIMA(0,0,2): second order of MA\n\n\n\n자기상관관계 부분\n\n\\[ Y_{t} = c + \\Phi_1 Y_{t-1} + \\varepsilon_{t} \\]\n\n\\(t\\) 시간에 관찰되는 변수 (\\(Y_{t}\\))는\n\n상수 (c) 더하기\n바로 1단위 전 변수 (\\(Y_{t-1}\\)) 에 계수(coefficient) (\\(\\Phi\\)) 글 곱한 값을 더하고\n현재의 에러를 \\(t (e_{t})\\)) 더한다\n\n\n\n이동평균 부분\n\n\\[ Y_{t} = c  + \\Theta_1 \\varepsilon_{t-1} + \\varepsilon_t \\]\n\n\\(t\\) 시간에 관찰되는 변수 (\\(Y_{t}\\))는\n\n상수 (c) 더하기\n바로 1단위 전 변수 (\\(\\varepsilon_{t-1}\\)) 에 계수(coefficient) (\\(\\Phi\\)) 글 곱한 값을 더하고\n현재의 에러를 \\(t (e_{t})\\)) 더한다\n\n\n\n결국 자기 상과관계와 이동평균을 한꺼번에 사용하면 아래와 같습니다.\n\n\\[\\begin{align*}\ny_t &= \\phi_1y_{t-1} + \\varepsilon_t\\\\\n&= \\phi_1(\\phi_1y_{t-2} + \\varepsilon_{t-1}) + \\varepsilon_t\\\\\n&= \\phi_1^2y_{t-2} + \\phi_1 \\varepsilon_{t-1} + \\varepsilon_t\\\\\n&= \\phi_1^3y_{t-3} + \\phi_1^2 \\varepsilon_{t-2} + \\phi_1 \\varepsilon_{t-1} + \\varepsilon_t\\\\\n\\end{align*}\\]\n\nd 는 시계열그림에서 ACF, PACF의 형태를 보고 차분의 필요여부 및 차수를 d를 결정하고 AR차수와 MA차수를 결정\n\n어떻게 p, d, q 를 구할수 있을 까요?, 다음 장을 보겠습니다. ** 다음에 기회가 있을 때 하겠습니다.**\n\n4.6.1 arima 감기 자살 , AIC\n아래 ARIMA 모델을 보면 AIC 가 6583정도 나온 것을 알 수 있습니다. 우리는 이것을 통해 AIC가 6583 이하 정도 나오는 gam 모델을 사용하겠다 정도의 개념을 얻었습니다.\n\npar(mfrow=c(1,1))\nauto.arima(myd$wsui)\n\nSeries: myd$wsui \nARIMA(0,1,2) \n\nCoefficients:\n          ma1      ma2\n      -0.3227  -0.0993\ns.e.   0.0379   0.0376\n\nsigma^2 = 756.3:  log likelihood = -3288.64\nAIC=6583.28   AICc=6583.31   BIC=6596.91\n\nmyd &lt;-myd %&gt;% mutate(ma4 =ma(wsui, order=4), ymd2=as.Date(ymd2) ) ### 4weeks moving average\nmyd &lt;-myd %&gt;% mutate(ts.wsui =tsui, ts.ma4=ts(ma4, frequency =365.25/7 ))\nm1&lt;-arima(myd$wsui, order=c(1,1,1), fixed=c(NA, NA)) ## NA means include, 0 means exclude\nm1\n\n\nCall:\narima(x = myd$wsui, order = c(1, 1, 1), fixed = c(NA, NA))\n\nCoefficients:\n         ar1      ma1\n      0.2294  -0.5589\ns.e.  0.0941   0.0797\n\nsigma^2 estimated as 755.2:  log likelihood = -3289.13,  aic = 6584.26\n\ntsdiag(m1)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>시계열분석</span>"
    ]
  },
  {
    "objectID": "timeseries_1.html#aic-bic-in-generalize-additive-model",
    "href": "timeseries_1.html#aic-bic-in-generalize-additive-model",
    "title": "4  시계열분석",
    "section": "4.7 AIC BIC in generalize additive model",
    "text": "4.7 AIC BIC in generalize additive model\n\ngg &lt;-function(x) {\n  model &lt;-glm(data=myd, wsui ~ ns(ymd2, x))\n  aic &lt;-AIC(model)\n  return(aic)\n  }\ngg2 &lt;-function(x) {\n  model &lt;-glm(data=myd, wsui ~ ns(ymd2, x))\n  bic &lt;-BIC(model)\n  return(bic)\n}\n\ntest &lt;-mapply(x=c(50:100), gg);test2&lt;-mapply(x=c(50:100), gg2)\n\npar(mfrow=c(1,2))\nplot(c(50:100), test);plot(c(50:100), test2)\nabline(v=64)\n\n\n\n\n\n\n\n\nAIC는 수렴하지 않아 어렵고, BIC는 64에서 최소 값을 보이네요. 64를 자유도로 선정하고 수행하겠습니다.\n\nmod1&lt;-glm (wsui ~ ns(ymd2, 64), data=myd)\nBIC(mod1)\n\n[1] 6790.573\n\n\nlong term trend (월)과 단기 trend 를 나누어 만들어 보면 어떨까요? 위에 64로 한번에 해결하는 게 더 좋은 모형 같습니다.\n\nmod1&lt;-glm( wsui ~ ns(ordweek, 12)+ns(nwd, 5), data=myd)\nBIC(mod1)\n\n[1] 6907.866\n\n\n기존의 sin cosin 방법으로 시계열 분석을 해보는 것은 어떨까요?\n\npar(mfrow=c(1,1))\nssp&lt;-spectrum(myd$wsui)\n\n\n\n\n\n\n\nper&lt;-1/ssp$freq[ssp$spec==max(ssp$spec)]\nsin.x&lt;-sin(2*pi*myd$ordweek/(365.25/7))\ncos.x&lt;-cos(2*pi*myd$ordweek/(365.25/7))\nmodsean &lt;-glm(wsui ~ ns(sin.x, 2)+ns(cos.x, 2), data=myd)\nmodlgam&lt;-glm(wsui ~ ns(ordweek, 4), data=myd)\n\nplot(myd$ymd2, myd$wsui, ylim=c(-10, 450), col='grey')\npoints(myd$ymd2, modlgam$fitted.values, type='l', col='blue')\npoints(myd$ymd2, modsean$fitted.values, type='l', col='blue')\n\n\n\n\n\n\n\n\n자 이제 2 모델을 검토해 보겠습니다. gam 과 sin cosin 모델 어떤게 더 좋아 보이시나요? 정해진 규칙은 겂습니다.\n\nplot(myd$ymd2, myd$wsui, ylim=c(-10, 450), col='grey')\npoints(myd$ymd2, modlgam$fitted.values, type='l', col='blue')\npoints(myd$ymd2, modsean$fitted.values, type='l', col='blue')\n\nmod1 &lt;-glm(wsui ~ flu+ns(ordweek, 51)+ns(sin.x, 2)+ns(cos.x, 2) , data=myd)\npoints(myd$ymd2, mod1$fitted.values, type='l', col='red')\nmodgam&lt;-glm (wsui ~ ns(ymd2, 64), data=myd)\npoints(myd$ymd2, modgam$fitted.values, type='l',  col='black')\n\n\n\n\n\n\n\n\n정해진 규칙은 없지만 AIC와 BIC로 비교해 볼수 있을 것 같습니다.\n\nAIC(mod1);AIC(modgam)\n\n[1] 6522.708\n\n\n[1] 6490.58\n\nBIC(mod1);BIC(modgam)\n\n[1] 6786.338\n\n\n[1] 6790.573\n\n\n이제 sin과 cos 에 어떠한 df를 주는 것이 좋을 까요?\n\nmyd$econo &lt;- ifelse(myd$YR %in% c(2009), 1, 0)\ngg &lt;-function(x) {\n  model &lt;-glm(data=myd, wsui ~ Lag(flu, 1)+ns(ordweek, 4)+ns(sin.x, x)+ns(cos.x, x))\n  aic &lt;-AIC(model)\n  return(aic)\n}\ngg &lt;-function(x) {\n  model &lt;-glm(data=myd, wsui ~ Lag(flu, 1)+ns(ordweek, 4)+ns(sin.x, x)+ns(cos.x, x))\n  bic &lt;-BIC(model)\n  return(bic)\n}\n\np&lt;-c(1:10)\ntest &lt;-mapply(x=p, gg);test2&lt;-mapply(x=p, gg2)\nplot(p, test)\n\n\n\n\n\n\n\nplot(p, test2)\n\n\n\n\n\n\n\n\n주중 효과 까지 한번 보겠습니다.\n\ngg &lt;-function(x) {\n  model &lt;-glm(data=myd, wsui ~ Lag(flu, 1)+ ns(ordweek, x)+ns(sin.x, 2)+ns(cos.x, 2))\n  aic &lt;-AIC(model)\n  return(aic)\n}\ngg2 &lt;-function(x) {\n  model &lt;-glm(data=myd, wsui ~ Lag(flu, 1)+ns(ordweek, x)+ns(sin.x, 2)+ns(cos.x, 2))\n  bic &lt;-BIC(model)\n  return(bic)\n}\ngg(10)\n\n[1] 6854.818\n\ntest\n\n [1] 7024.330 6937.360 6937.973 6949.360 6961.920 6963.986 6982.745 6988.485\n [9] 6998.475 7012.750\n\np&lt;-c(10:100)\ntest &lt;-mapply(x=p, gg);test2&lt;-mapply(x=p, gg2)\npar(mfrow=c(1,2))\nplot(p, test)\nabline(v=39)\nplot(p, test2)\nabline(v=39)\n\n\n\n\n\n\n\n\n최종 모델은 아래와 같습니다.\n\nmod2 &lt;-glm(data=myd, wsui ~ flu+ ns(ordweek, 39)+ns(sin.x, 2)+ns(cos.x, 2))\npar(mfrow=c(1,1))\nplot(myd$ymd2, myd$wsui, cex=0.5, col='grey', ylim=c(-50, 450))\npoints(myd$ymd2, mod2$fitted.values, type='l', col='red')\n\n\n\n\n\n\n\nBIC(mod2)\n\n[1] 6785.128\n\nAIC(mod2)\n\n[1] 6576.042\n\n\n그럼 이제 lag time 을 non-linear 로 할때 몇차 방정식이 좋을까요? 둘다 2차 방정식이 좋네요\n\ngg3&lt;-function(pp){\n  cb&lt;- crossbasis(myd$flu/10, lag=24, argvar=list(\"lin\"),  arglag = list(fun=\"poly\", degree=pp))\n  model&lt;-glm(data=myd, wsui ~ cb + ns(ordweek, 39)+ns(sin.x, 2)+ns(cos.x, 2))\n  aic&lt;-AIC(model)\n  return(aic)\n}\ngg4&lt;-function(pp){\n  cb1&lt;- crossbasis(myd$flu/10, lag=24, argvar=list(\"lin\"),  arglag = list(fun=\"poly\", degree=pp))\n  model1&lt;-glm(data=myd, wsui ~ cb1 + ns(ordweek, 39)+ns(sin.x, 2)+ns(cos.x, 2))\n  bic&lt;-BIC(model1)\n  return(bic)\n}\np&lt;-c(2:10)\ntest3 &lt;-mapply(pp=p, gg3);test4 &lt;-mapply(pp=p, gg4)\npar(mfrow=c(1,2))\nplot(p, test3)\n\nplot(p, test4)\n\n\n\n\n\n\n\n\n종합해서 나타내 보겠습니다. 이것이 첫번째 종착지 입니다.\n\npar(mfrow=c(1,1))\ncb1&lt;- crossbasis(myd$flu/10, lag=24, argvar=list(\"lin\"),  arglag = list(fun=\"poly\", degree=2))\nmodel1&lt;-glm(data=myd, wsui ~ cb1 + ns(ordweek, 39)+ns(sin.x, 2)+ns(cos.x, 2), family=quasipoisson())\n\npred1.cb1 &lt;-crosspred(cb1, model1, at=1:100, bylag=0.1,  cumul=TRUE)\nplot(pred1.cb1, \"slices\", var=1, col=3, ylab=\"Relative risk of suicide\", #ci.arg=list(density=50, lwd=1),#\n     main=\"Temporal effect by influenza\", \n     xlab=\"Lag (weeks)\",  #ylim=c(0.980, 1.02),\n     col='black') ;grid()\ntitle(main=\"% increment of influenza like illness\", \n       \n      adj=1, line=0, font.main=3, cex=0.5 )\n\nlin &lt;-c(5:10)\nabline(v=lin, lty=3, col='lightgray')\naxis(side=1, at=c(6, 7, 8, 9))\n\n\n\n\n\n\n\n\n2009년 이전과 이후를 그려보겠습니다.\n\nmyd2&lt;-myd %&gt;% mutate(sinx=sin.x, cosx=cos.x) %&gt;% mutate(flu210=flu/10)\nmf1d &lt;-myd2 %&gt;% filter(YR &lt;=2008)\nmf2d &lt;-myd2 %&gt;% filter (YR&gt;=2009)\nmf1 &lt;-glm(data=mf1d, wsui ~ flu + ns(ordweek, 25)+ns(sinx, 2)+ns(cosx, 2), family=quasipoisson())\nmf1s&lt;-glm(data=mf1d , flu210 ~ ns(ordweek, 25)+ns(sinx, 2)+ns(cosx,2), family=quasipoisson())\nb2008&lt;-summary(mf1)$coefficient[2,]\nmf2 &lt;-glm(data=mf2d, wsui ~ flu + ns(ordweek, 22)+ns(sinx, 2)+ns(cosx, 2), family=quasipoisson())\nmf2s &lt;-glm(data=mf2d, flu210 ~ns(ordweek, 25)+ns(sinx, 2)+ns(cosx,2), family=quasipoisson())\nf2008&lt;-summary(mf2)$coefficient[2,]\nmfresid&lt;-c(mf1$residuals, mf2$residuals)\nCh &lt;-c(myd2$Change_2008)\n\nWarning: Unknown or uninitialised column: `Change_2008`.\n\n#exp(cbind(\"Relative Risk\"=coef(mf2), confint.default(mf2, level = 0.95)))\n#exp(cbind(\"Relative Risk\"=coef(mf1), confint.default(mf1, level = 0.95)))\n\n\n# E(Y) = intercept + B1X1 +gam(others)\n# E(Y)- intercept - B1X1 = gam(otehrs)\ngamothers1 &lt;- mf1$fitted.values - 0.943684 -(-0.013931) *mf1d$flu210\ngamothers2 &lt;- mf2$fitted.values - 0.8892468 -(0.0023323696) *mf2d$flu210\n# E(Y)- intercept - gam(others)= B1X1  \n# Hence Y axis = E(Y)- intercept - gam(others)\nYaxis.mf1d &lt;- mf1$fitted.values -(0.943684) - gamothers1\nYaxis.mf2d &lt;- mf2$fitted.values -(0.8892468) - gamothers2\n\nmf1d$Yaxis.mf &lt;-Yaxis.mf1d\nmf2d$Yaxis.mf &lt;-Yaxis.mf2d\nplot(mf1d$flu210, Yaxis.mf1d)\n\n\n\n\n\n\n\nplot(mf2d$flu210, Yaxis.mf2d)\n\n\n\n\n\n\n\nplot(myd2$flu210*10, myd2$wsui)\n\n\n\n\n\n\n\n#summary(glm(Yaxis.mf1d ~ mf1d$flu210))\n#summary(glm(Yaxis.mf2d ~ mf2d$flu210))\n\ntt &lt;-c(mf1d$Yaxis.mf, mf2d$Yaxis.mf)\ntt2&lt;-c(mf1$fitted.values, mf2$fitted.values)\nmyd2 &lt;-myd2 %&gt;% mutate(Yaxis.mf =tt, mfresid =mfresid, mf.fit=tt2)\n\n2009년 이후로 좀더 사망하게 되네요.\n\nf3&lt;-ggplot(data=myd2, aes(flu210, Yaxis.mf, col=Change))+geom_line(size=1)+\n  geom_point(data=myd2, aes(flu210, Yaxis.mf, shape=Change), size=0.0)+\n  theme_bw(base_size=14,base_family='Times New Roman')+ \n  theme(panel.border = element_blank(), axis.line = element_line(colour = \"black\"),\n        axis.text.x=element_text(size=12),\n        axis.text.y=element_text(size=12))+\n  xlab(\"Influenza\") +ylab(\"Increment of Suicide\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nfig3 &lt;-f3 + geom_point(aes(flu210, mfresid, shape=Change), size=3 ) +\n    scale_shape_manual(values=c(1, 20))+ scale_colour_manual(values=c('red', 'grey45'))+ \n     theme(legend.position=\"right\") + \n  labs(title=\"Linear relationship between Influenza and Suicide\",\n       subtitle=\"Beta = -0.066, p = 0.214  before 2009\\n  *RR =  0.013,  p = 0.018     from 2009\") +\n      theme(plot.subtitle=element_text(size=12, hjust=1, face=\"italic\", color=\"black\")) +\n  scale_x_continuous(trans = 'log')\n\nfig3\n\nWarning in scale_x_continuous(trans = \"log\"): log-2.718282 transformation\nintroduced infinite values.\n\n\nWarning in scale_x_continuous(trans = \"log\"): log-2.718282 transformation introduced infinite values.\nlog-2.718282 transformation introduced infinite values.\n\n\n\n\n\n\n\n\n\n지금까지의 내용을 정리해 보겠습니다.\n\nmf11 &lt;-glm(data=mf1d , wsui ~ ns(ordweek, 25)+ns(sinx, 2)+ns(cosx,2))\nmf12 &lt;-glm(data=mf2d, wsui ~ ns(ordweek, 22)+ns(sinx, 2)+ns(cosx, 2))\ntt3&lt;-c(mf11$residuals, mf12$residuals)\nmyd2&lt;-myd2 %&gt;% mutate(f3resid=tt3) %&gt;% mutate(Period=Change)\n\nf1&lt;-ggplot(data=myd2, aes(ymd2, wsui, shape=Change), size=0.3)+ scale_shape_manual(values=c(1, 19), name=\"\")+ \n    geom_point(data=myd2, aes(ymd2, wsui, shape=Change))+\n    #geom_point(aes(x=ymd2, y=f3resid, col=Change)) +\n    geom_line(data=myd2, aes(ymd2, mod2$fitted.values, linetype=\"A\", color='A'))+\n    geom_line(data=myd2, aes(ymd2,flu210*20, linetype=\"B\", color='B'))+\n    geom_line(data=myd2, aes(ymd2, f3resid, linetype=\"C\", color='C'))+\n    \n    scale_linetype_manual(values=c(A=\"dotted\", B=\"solid\", C=\"dashed\"), \n                        labels=c(\"Suicide (Crude)\", \"Influenza like illness\", \"Suicide \\n(Time series adjusted)\"), \n                        name=\"Suicide and Influenza\")+ \n  \n    scale_color_manual(values=c(A=\"black\", B=\"blue\", C=\"red\"), \n                        labels=c(\"Suicide (Crude)\", \"Influenza like illness\", \"Suicide \\n(Time series adjusted)\"), \n                        name=\"Suicide and Influenza\")+ \n  \n  theme(panel.border = element_blank(), axis.line = element_line(colour = \"black\"),\n                                                              axis.text.x=element_text(size=12),\n                                                              axis.text.y=element_text(size=12)) +\n  xlab(\"Years (unit=weeks)\") +ylab(\"Number of weekly suicide\")\n   \n  figure1 &lt;- f1 +\n    geom_smooth(aes(ymd2, f3resid), method='gam', formula=y ~ns(x, 60),\n                se=TRUE, col='red', linetype=\"solid\", size=0.3, fill = 'red')+\n    theme( legend.position =   \"right\") + \n    labs(caption =\"*Beta = weekly suicide number change by % increment of influenza like illness\",\n      title=\"\"#, subtitle=\"Beta = -0.014, p = 0.158  before 2009\\n  Beta =  0.002,  p = 0.011     from 2009\"\n         ) +   theme(plot.title=element_text(size=16, hjust=0.5)) + #face=\"italic\", color=\"black\"))+\n  theme(legend.text=element_text(size=12)) +\n    scale_y_continuous(sec.axis = sec_axis((~./20), name=\"Influenza like illness ( per 100 outpatient )\")) +\n    annotate(\"text\", x = as.Date('2008-09-01'), y = 450, label = 'bold(\"Before 2009 (  )\")', parse=TRUE, family='A', hjust = 1) +\n    annotate(\"text\", x = as.Date('2008-09-01'), y = 430, label = 'italic(\"*Beta = -0.066\")', parse=TRUE, family='A', hjust = 1) + \n    annotate(\"text\", x = as.Date('2008-09-01'), y = 410, label = 'italic(\" p = 0.214\")', parse=TRUE, family='A', hjust = 1) + \n    guides(shape=FALSE)+\n    annotate(\"text\", x = as.Date('2012-01-01'), y = 450, label = 'bold(\"From  2009 (  )\")', parse=TRUE, family='A', hjust = 0) +\n    annotate(\"text\", x = as.Date('2012-01-01'), y = 430, label = 'italic(\"*Beta = 0.013\")', parse=TRUE, family='A', hjust = 0) + \n    annotate(\"text\", x = as.Date('2012-01-01'), y = 410, label = 'italic(\" p = 0.019\")', parse=TRUE, family='A', hjust = 0) +\n    geom_point(x=as.Date('2008-06-25'), y=449, size=3, shape=1) +\n    geom_point(x=as.Date('2013-11-01'), y=449, size=3, shape=19) +\n    geom_vline(xintercept = as.Date('2009-01-01'), linetype=\"dotted\", \n                    color = \"grey50\") #+\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n    #annotate(\"rect\", xmin = as.Date('2004-06-01'), xmax = as.Date('2009-01-01'),  ymin = -50, ymax = 470,\n     #       alpha = .1)\n  \n\n        \n  \n  figure1 \n\n\n\n\n\n\n\n\n여기 까지 실습하시느라 수고하셨습니다. 상기 분석 방법으로 아래 논문을 출판하였습니다. 참고해서 보시면 좋겠습니다. https://journals.plos.org/plosone/article/comments?id=10.1371/journal.pone.0244596",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>시계열분석</span>"
    ]
  },
  {
    "objectID": "InterruptedTS.html",
    "href": "InterruptedTS.html",
    "title": "5  중단된 시계열 분석",
    "section": "",
    "text": "5.1 서론\n오늘 강의에서는 중단된 시계열 분석(Interrupted Time Series, ITS)이라는 강력한 통계 기법을 소개하고, 이를 산업보건 분야에 어떻게 적용할 수 있는지 살펴보겠습니다. ITS 분석은 특정 개입(intervention)이 시계열 데이터에 미치는 영향을 평가하는 데 사용됩니다.\n참고자료: https://rpubs.com/chrissyhroberts/1006858\n강의 내용:\n본 강의에서는 다음과 같은 세 가지 주요 유형의 ITS 분석을 예시와 함께 설명합니다. 각 예시에서는 산업보건 상황을 가정하여 데이터 생성부터 모델링, 결과 해석까지의 전 과정을 단계별로 안내합니다.\nITS 분석의 핵심은 반사실적 시나리오의 개념입니다. 우리는 실제로 발생한 사건(사실적 시나리오)을 모델링하고, 만약 개입이 없었다면 어떤 일이 발생했을지(반사실적 시나리오)를 추정합니다. 그리고 사실적 시나리오와 반사실적 시나리오를 비교하여 개입의 영향을 평가합니다.\n예를 들어, 공장의 작업 환경 개선을 위한 새로운 안전 수칙 도입이 산업재해 발생 건수에 미치는 영향을 평가한다고 가정해 봅시다. ITS 분석을 통해 안전 수칙 도입 후의 실제 산업재해 발생 건수 변화를 모델링하고, 만약 안전 수칙이 도입되지 않았다면 산업재해 발생 건수가 어떻게 변화했을지를 추정하여 그 차이를 분석합니다.\n개입으로 인한 변화의 유형 개입으로 인해 데이터에서 나타날 수 있는 변화는 다음과 같은 두 가지 주요 형태를 가질 수 있습니다.\n실제 산업보건 상황을 고려하여 어떤 유형의 변화가 발생할 가능성이 있는지 신중하게 판단하고, 이에 맞는 모델을 구축해야 합니다",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>중단된 시계열 분석</span>"
    ]
  },
  {
    "objectID": "InterruptedTS.html#서론",
    "href": "InterruptedTS.html#서론",
    "title": "5  중단된 시계열 분석",
    "section": "",
    "text": "파트 1: 통제되지 않은 ITS (Uncontrolled ITS), 단일 개입\n파트 2: 통제되지 않은 ITS (Uncontrolled ITS), 두 번의 개입\n파트 3: 통제된 ITS (Controlled ITS), 단일 개입\n\n\n핵심 개념: 반사실적 시나리오 (Counterfactual Scenario)\n\n\n\n\n\n단계 변화 (Step Change): 개입 직후 즉각적이고 급격한 변화. 예를 들어, 새로운 안전 장비 도입으로 인해 산업재해 발생 건수가 갑자기 감소하는 경우입니다.\n추세 변화 (Slope/Trend Change): 개입 이후 데이터의 추세가 변화하는 것. 예를 들어, 건강 증진 프로그램 시행 후 시간이 지남에 따라 근로자들의 결근율이 점진적으로 감소하거나, 초기 감소 후 다시 증가하는 경우도 있을 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>중단된 시계열 분석</span>"
    ]
  },
  {
    "objectID": "InterruptedTS.html#통제되지-않은-its-uncontrolled-its-단일-개입",
    "href": "InterruptedTS.html#통제되지-않은-its-uncontrolled-its-단일-개입",
    "title": "5  중단된 시계열 분석",
    "section": "5.2 통제되지 않은 ITS (Uncontrolled ITS), 단일 개입",
    "text": "5.2 통제되지 않은 ITS (Uncontrolled ITS), 단일 개입\n가장 기본적인 형태의 ITS 분석으로, 하나의 개입이 단일 결과 변수에 미치는 영향을 평가합니다.\n가상 데이터 생성:\n\n다음은 가상의 산업보건 데이터를 생성하는 R 코드입니다. 특정 작업장의 주간 산업재해 발생 건수를 측정했으며, 51주차에 새로운 안전 교육 프로그램을 도입했다고 가정합니다.\n\n\nlibrary(tidyverse)\nlibrary(nlme)\nlibrary(AICcmodavg)\nlibrary(DT)\n\n# 개입 시점: 51주차\ndf &lt;- tibble(\n  Time = 1:100, # 연구 주 (1 - 100주)\n  Intervention = c(rep(0, 50), rep(1, 50)), # 개입 여부 (개입 전: 0, 개입 후: 1)\n  Post.intervention.time = c(rep(0, 50), 1:50), # 개입 후 경과 시간\n  quantity.x = c(sort(sample(20:50, size = 50, replace = T), decreasing = T) + sample(-5:5, 50, replace = T), # 개입 전 주간 재해 건수 (가상 데이터)\n                 c(sort(sample(5:30, size = 50, replace = T), decreasing = T) + sample(-10:10, 50, replace = T))) # 개입 후 주간 재해 건수 (가상 데이터)\n)\n\ndatatable(df, options = list(pageLength = 100, scrollY = \"200px\"))\n\n\n\n\n\n위 코드는 다음과 같은 변수를 포함하는 데이터 프레임을 생성합니다.\n\nTime: 연구가 진행된 주차 (1부터 100까지).\nIntervention: 개입이 발생했는지 여부를 나타내는 이진 변수 (개입 전 50주 동안은 0, 개입 후 50주 동안은 1).\nPost.intervention.time: 개입이 발생한 후 경과된 시간 (개입 전에는 0, 개입 후에는 1부터 50까지).\nquantity.x: 우리가 측정하고자 하는 결과 변수 (여기서는 주간 산업재해 발생 건수).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>중단된 시계열 분석</span>"
    ]
  },
  {
    "objectID": "InterruptedTS.html#기본-its-모델-구축",
    "href": "InterruptedTS.html#기본-its-모델-구축",
    "title": "5  중단된 시계열 분석",
    "section": "5.3 기본 ITS 모델 구축:",
    "text": "5.3 기본 ITS 모델 구축:\n가장 단순한 형태의 ITS 모델은 일반화 최소 제곱(Generalized Least Squares, GLS) 회귀 분석을 사용하여 구축할 수 있습니다.\n\nmodel.a &lt;- gls(quantity.x ~ Time + Intervention + Post.intervention.time, data = df, method = \"ML\")\nsummary(model.a)\n\nGeneralized least squares fit by maximum likelihood\n  Model: quantity.x ~ Time + Intervention + Post.intervention.time \n  Data: df \n       AIC      BIC    logLik\n  613.0613 626.0871 -301.5306\n\nCoefficients:\n                          Value Std.Error   t-value p-value\n(Intercept)            48.60082 1.4462745  33.60414  0.0000\nTime                   -0.61729 0.0493606 -12.50566  0.0000\nIntervention           12.26190 2.0153402   6.08428  0.0000\nPost.intervention.time  0.15539 0.0698065   2.22601  0.0284\n\n Correlation: \n                       (Intr) Time   Intrvn\nTime                   -0.870              \nIntervention            0.348 -0.600       \nPost.intervention.time  0.615 -0.707 -0.017\n\nStandardized residuals:\n        Min          Q1         Med          Q3         Max \n-2.49017923 -0.67118359  0.02948247  0.79956857  1.90310826 \n\nResidual standard error: 4.935074 \nDegrees of freedom: 100 total; 96 residual\n\n\n모델의 계수는 다음과 같은 의미를 갖습니다.\n\n(Itercept): 연구 시작 시점의 quantity.x의 추정 값.\nTime: 개입 전 시간의 흐름에 따른 quantity.x의 변화 추세 (주당 변화량).\nIntervention: 개입 시점에서의 즉각적인 단계 변화 크기.\nPost.intervention.time: 개입 이후 시간의 흐름에 따른 quantity.x의 변화 추세 변화량 (개입 전 추세에 추가되는 주당 변화량).\n\n\n5.3.1 모델 예측값 및 신뢰 구간 추가:\n모델에서 예측된 값과 표준 오차를 데이터 프레임에 추가하여 시각화하고 신뢰 구간을 계산할 수 있습니다.\n\ndf &lt;- df %&gt;% mutate(\n  model.a.predictions = predictSE.gls(model.a, df, se.fit = T)$fit,\n  model.a.se = predictSE.gls(model.a, df, se.fit = T)$se\n)\n\n\nlibrary(ggplot2)\n\nggplot(df, aes(Time, quantity.x)) +\n  geom_ribbon(aes(ymin = model.a.predictions - (1.96 * model.a.se), ymax = model.a.predictions + (1.96 * model.a.se)), fill = \"lightgreen\") +\n  geom_line(aes(Time, model.a.predictions), color = \"black\", lty = 1) +\n  geom_point(alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\n5.3.2 자기상관 (Autocorrelation) 처리:\n시계열 데이터는 종종 자기상관이라는 특성을 가집니다. 이는 특정 시점의 값이 이전 시점의 값과 상관 관계를 갖는 현상입니다. 자기상관을 무시하면 모델 추정치의 효율성과 신뢰성이 저하될 수 있습니다.\nGLS 모델에서는 corARMA 함수를 사용하여 자기상관을 고려할 수 있습니다. p는 자기 회귀 차수(autoregressive order), q는 이동 평균 차수(moving average order)를 나타냅니다. 적절한 p와 q 값을 선택하는 것은 중요하며, AIC (Akaike Information Criterion)와 같은 정보 기준을 사용하여 최적의 모델을 선택할 수 있습니다.\n\n# 자기상관 모델 구축 및 AIC 비교 함수\nmod.1 &lt;- quantity.x ~ Time + Intervention + Post.intervention.time\n\nfx &lt;- function(pval, qval) {\n  summary(gls(mod.1, data = df, correlation = corARMA(p = pval, q = qval, form = ~ Time), method = \"ML\"))$AIC\n}\n\n# 비상관 모델의 AIC\np &lt;- summary(gls(mod.1, data = df, method = \"ML\"))$AIC\nmessage(str_c(\"AIC Uncorrelated model = \", p))\n\nAIC Uncorrelated model = 613.06125479172\n\n# p와 q의 다양한 조합에 대한 AIC 계산\nautocorrel &lt;- expand.grid(pval = 0:2, qval = 0:2)\nfor (i in 2:nrow(autocorrel)) {\n  p[i] &lt;- try(summary(gls(mod.1, data = df, correlation = corARMA(p = autocorrel$pval[i], q = autocorrel$qval[i], form = ~ Time), method = \"ML\"))$AIC)\n}\n\nautocorrel &lt;- autocorrel %&gt;%\n  mutate(AIC = as.numeric(p)) %&gt;%\n  arrange(AIC)\n\nautocorrel\n\n  pval qval      AIC\n1    0    0 613.0613\n2    1    0 615.0468\n3    0    1 615.0496\n4    0    2 615.5883\n5    2    0 615.6401\n6    1    1 616.2963\n7    2    1 617.1825\n8    1    2 617.3935\n9    2    2 619.0693\n\n\nAIC 값이 가장 낮은 모델이 데이터에 가장 적합한 자기상관 구조를 나타냅니다. 최적의 p와 q 값을 사용하여 최종 모델을 구축합니다.\n\n# 최적의 p=2, q=2를 적용한 모델\nmodel.b &lt;- gls(quantity.x ~ Time + Intervention + Post.intervention.time, data = df, method = \"ML\", correlation = corARMA(p = 2, q = 2, form = ~ Time))\ncoefficients(model.a)\n\n           (Intercept)                   Time           Intervention \n            48.6008163             -0.6172869             12.2618968 \nPost.intervention.time \n             0.1553902 \n\ncoefficients(model.b)\n\n           (Intercept)                   Time           Intervention \n            48.5763444             -0.6162835             12.2327330 \nPost.intervention.time \n             0.1540193 \n\n# 모델 b의 예측값 및 표준 오차 추가\ndf &lt;- df %&gt;%\n  mutate(\n    model.b.predictions = predictSE.gls(model.b, df, se.fit = T)$fit,\n    model.b.se = predictSE.gls(model.b, df, se.fit = T)$se\n  )\n\n\n\n5.3.3 반사실적 모델 (Counterfactual Model) 구축:\n개입이 없었다면 어떤 일이 발생했을지를 추정하기 위해 반사실적 모델을 구축합니다. 이는 개입 이전의 데이터만을 사용하여 시간 추세를 모델링하고, 이를 개입 이후 시점까지 외삽하는 방식으로 이루어집니다.\n\n# 개입 이전 데이터 필터링\ndf2 &lt;- filter(df, Time &lt; 51)\n\n# 반사실적 모델 구축\nmodel.c &lt;- gls(quantity.x ~ Time, data = df2, correlation = corARMA(p = 1, q = 1, form = ~ Time), method = \"ML\")\ncoefficients(model.a)\n\n           (Intercept)                   Time           Intervention \n            48.6008163             -0.6172869             12.2618968 \nPost.intervention.time \n             0.1553902 \n\ncoefficients(model.c)\n\n(Intercept)        Time \n  48.545253   -0.615377 \n\n# 반사실적 모델 예측값 및 표준 오차 추가\ndf &lt;- df %&gt;% mutate(\n  model.c.predictions = predictSE.gls(model.c, newdata = df, se.fit = T)$fit,\n  model.c.se = predictSE.gls(model.c, df, se.fit = T)$se\n)\n\n\n사실적 모델과 반사실적 모델 비교 시각화:\n\n사실적 모델과 반사실적 모델의 예측값 및 신뢰 구간을 함께 시각화하여 개입의 영향을 평가합니다.\n\nggplot(df, aes(Time, quantity.x)) +\n  geom_ribbon(aes(ymin = model.c.predictions - (1.96 * model.c.se), ymax = model.c.predictions + (1.96 * model.c.se)), fill = \"pink\") +\n  geom_line(aes(Time, model.c.predictions), color = \"red\", lty = 2) +\n  geom_ribbon(aes(ymin = model.b.predictions - (1.96 * model.b.se), ymax = model.b.predictions + (1.96 * model.b.se)), fill = \"lightgreen\") +\n  geom_line(aes(Time, model.b.predictions), color = \"black\", lty = 1) +\n  geom_point(alpha = 0.3)\n\n\n\n\n\n\n\n\n만약 사실적 모델의 신뢰 구간과 반사실적 모델의 신뢰 구간이 겹치지 않는다면, 개입이 결과 변수에 통계적으로 유의미한 영향을 미쳤다고 해석할 수 있습니다. 또한, 두 선의 차이가 시간이 지남에 따라 벌어진다면, 개입이 추세 변화를 유발했을 가능성을 시사합니다.\n\n\n5.3.4 개입 효과의 크기 추정:\n사실적 모델의 예측값에서 반사실적 모델의 예측값을 빼서 각 시점에서의 개입 효과 크기를 추정할 수 있습니다.\n\nformat(df$model.b.predictions - df$model.c.predictions, scientific = F)[c(1, 50, 51, 100)]\n\n              1              50              51             100 \n\" 0.0301844808\" \"-0.0142302631\" \"12.3716156541\" \"19.8741489561\"",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>중단된 시계열 분석</span>"
    ]
  },
  {
    "objectID": "InterruptedTS.html#통제되지-않은-its-uncontrolled-its-두-번의-개입",
    "href": "InterruptedTS.html#통제되지-않은-its-uncontrolled-its-두-번의-개입",
    "title": "5  중단된 시계열 분석",
    "section": "5.4 통제되지 않은 ITS (Uncontrolled ITS), 두 번의 개입",
    "text": "5.4 통제되지 않은 ITS (Uncontrolled ITS), 두 번의 개입\nITS 모델은 여러 번의 개입이 있는 경우에도 확장하여 적용할 수 있습니다. 예를 들어, 산업보건 개입이 여러 단계로 이루어지거나, 예상치 못한 사건이 발생하는 경우를 분석할 수 있습니다.\n\n가상 데이터 생성:\n\n다음은 두 번의 개입이 있는 가상 데이터를 생성하는 R 코드입니다. 첫 번째 안전 교육 프로그램 도입(51주차)과 추가적인 작업 환경 개선(101주차)이 주간 산업재해 발생 건수에 미치는 영향을 평가한다고 가정합니다.\n\n# 두 번의 개입 시점: 51주차, 101주차\ndf3 &lt;- tibble(\n  Time = 1:150,\n  Intervention = c(rep(0, 50), rep(1, 100)), # 첫 번째 개입 여부\n  Post.intervention.time = c(rep(0, 50), 1:100), # 첫 번째 개입 후 경과 시간\n  Intervention.2 = c(rep(0, 100), rep(1, 50)), # 두 번째 개입 여부\n  Post.intervention.2.time = c(rep(0, 100), 1:50), # 두 번째 개입 후 경과 시간\n  quantity.x = c(sort(sample(40:70, size = 50, replace = T), decreasing = T) + sample(-5:5, 50, replace = T),\n                 c(sort(sample(15:45, size = 50, replace = T), decreasing = T) + sample(-10:10, 50, replace = T)),\n                 c(sort(sample(5:30, size = 50, replace = T), decreasing = F) + sample(-5:5, 50, replace = T)))\n)\n\ndatatable(df3, options = list(pageLength = 100, scrollY = \"200px\"))\n\n\n\n\n\n\nITS 모델 구축:\n\n두 번의 개입을 고려한 ITS 모델은 다음과 같이 구축할 수 있습니다.\n\nmodel.d &lt;- gls(quantity.x ~ Time + Intervention + Post.intervention.time + Intervention.2 + Post.intervention.2.time,\n               data = df3, method = \"ML\", correlation = corARMA(p = 2, q = 2, form = ~ Time))\nsummary(model.d)\n\nGeneralized least squares fit by maximum likelihood\n  Model: quantity.x ~ Time + Intervention + Post.intervention.time + Intervention.2 +      Post.intervention.2.time \n  Data: df3 \n       AIC      BIC    logLik\n  899.3558 932.4728 -438.6779\n\nCorrelation Structure: ARMA(2,2)\n Formula: ~Time \n Parameter estimate(s):\n      Phi1       Phi2     Theta1     Theta2 \n-0.9905240 -0.9437959  0.8928560  0.9050067 \n\nCoefficients:\n                            Value Std.Error   t-value p-value\n(Intercept)              70.22011 1.2568025  55.87204  0.0000\nTime                     -0.61536 0.0428838 -14.34937  0.0000\nIntervention              6.21757 1.7500652   3.55276  0.0005\nPost.intervention.time   -0.02452 0.0606429  -0.40441  0.6865\nIntervention.2           -8.00397 1.7500783  -4.57349  0.0000\nPost.intervention.2.time  1.11718 0.0606429  18.42222  0.0000\n\n Correlation: \n                         (Intr) Time   Intrvn Pst.n. Intr.2\nTime                     -0.870                            \nIntervention              0.348 -0.600                     \nPost.intervention.time    0.616 -0.707 -0.017              \nIntervention.2            0.000  0.000  0.250 -0.424       \nPost.intervention.2.time  0.000  0.000  0.441 -0.500 -0.018\n\nStandardized residuals:\n        Min          Q1         Med          Q3         Max \n-2.41985986 -0.75217306  0.02668579  0.65804934  2.41400886 \n\nResidual standard error: 4.690972 \nDegrees of freedom: 150 total; 144 residual\n\n\n새로운 계수는 두 번째 개입의 즉각적인 단계 변화(Intervention.2)와 두 번째 개입 이후의 추세 변화(Post.intervention.2.time)를 나타냅니다.\n\n모델 예측값 및 시각화:\n\n이제 구축한 모델 model.d를 사용하여 예측값을 생성하고, 이를 시각화하여 두 번의 개입이 산업재해 발생 건수에 미치는 영향을 살펴봅니다.\n\ndf3 &lt;- df3 %&gt;% mutate(\n  model.d.predictions = predictSE.gls(model.d, df3, se.fit = T)$fit,\n  model.d.se = predictSE.gls(model.d, df3, se.fit = T)$se\n)\n\nggplot(df3, aes(Time, quantity.x)) +\n  geom_ribbon(aes(ymin = model.d.predictions - (1.96 * model.d.se), ymax = model.d.predictions + (1.96 * model.d.se)), fill = \"lightgreen\") +\n  geom_line(aes(Time, model.d.predictions), color = \"black\", lty = 1) +\n  geom_point(alpha = 0.3) +\n  labs(\n    title = \"두 번의 개입이 있는 통제되지 않은 ITS 분석\",\n    x = \"주차\",\n    y = \"주간 산업재해 발생 건수\"\n  )\n\n\n\n\n\n\n\n\n위 그래프는 실제 산업재해 발생 건수(점), 모델이 예측한 추세선(검은색 실선), 그리고 모델 예측의 95% 신뢰 구간(녹색 리본)을 보여줍니다. 그래프를 통해 두 번의 개입 시점(51주차, 101주차)에서 산업재해 발생 건수의 변화가 시각적으로 확인될 수 있습니다.\n\n5.4.1 반사실적 시나리오 분석 (두 번의 개입):\n두 번의 개입이 있는 경우, 다양한 반사실적 시나리오를 고려할 수 있습니다. 예를 들어,\n\n만약 어떠한 개입도 없었다면?\n만약 첫 번째 개입만 있었다면?\n\n각각의 반사실적 시나리오를 모델링하고 실제 결과와 비교하여 각 개입의 순수한 효과를 추정할 수 있습니다.\n1). 첫 번째 반사실적 모델 (어떠한 개입도 없었던 경우):\n개입 이전 데이터(50주차까지)만을 사용하여 시간 추세를 모델링하고, 전체 기간으로 외삽합니다.\n\ndf4 &lt;- filter(df3, Time &lt; 51)\nmodel.e &lt;- gls(quantity.x ~ Time, data = df4, correlation = corARMA(p = 1, q = 1, form = ~ Time), method = \"ML\")\n\ndf3 &lt;- df3 %&gt;% mutate(\n  model.e.predictions = predictSE.gls(model.e, newdata = df3, se.fit = T)$fit,\n  model.e.se = predictSE.gls(model.e, df3, se.fit = T)$se\n)\n\n\n두 번째 반사실적 모델 (첫 번째 개입만 있었던 경우):\n\n첫 번째 개입 이전과 이후 데이터(100주차까지)를 사용하여 첫 번째 개입의 효과를 모델링하고, 전체 기간으로 외삽합니다.\n\ndf5 &lt;- filter(df3, Time &lt; 101)\nmodel.f &lt;- gls(quantity.x ~ Time + Intervention + Post.intervention.time,\n               data = df5, correlation = corARMA(p = 1, q = 1, form = ~ Time), method = \"ML\")\n\ndf3 &lt;- df3 %&gt;% mutate(\n  model.f.predictions = predictSE.gls(model.f, newdata = df3, se.fit = T)$fit,\n  model.f.se = predictSE.gls(model.f, df3, se.fit = T)$se\n)\n\n\n\n5.4.2 사실적 모델과 반사실적 모델 비교 시각화 (두 번의 개입):\n이제 사실적 모델(model.d)과 두 가지 반사실적 모델(model.e, model.f)의 예측값을 함께 시각화하여 각 개입의 효과를 비교합니다.\n\nggplot(df3, aes(Time, quantity.x)) +\n  geom_ribbon(aes(ymin = model.f.predictions - (1.96 * model.d.se), ymax = model.f.predictions + (1.96 * model.e.se), fill = \"lightblue\", alpha = 0.4)) +\n  geom_line(aes(Time, model.f.predictions), color = \"blue\", lty = 2) + # 첫 번째 개입만 있었을 경우\n  geom_ribbon(aes(ymin = model.e.predictions - (1.96 * model.d.se), ymax = model.e.predictions + (1.96 * model.e.se), fill = \"pink\", alpha = 0.4)) +\n  geom_line(aes(Time, model.e.predictions), color = \"red\", lty = 2) + # 어떠한 개입도 없었을 경우\n  geom_ribbon(aes(ymin = model.d.predictions - (1.96 * model.d.se), ymax = model.d.predictions + (1.96 * model.d.se), fill = \"lightgreen\", alpha = 0.4)) +\n  geom_line(aes(Time, model.d.predictions), color = \"black\", lty = 1) + # 실제 데이터 모델\n  geom_point(alpha = 0.3) +\n  labs(\n    title = \"두 번의 개입에 대한 사실적 및 반사실적 시나리오 비교\",\n    x = \"주차\",\n    y = \"주간 산업재해 발생 건수\",\n    fill = \"시나리오\",\n    color = \"시나리오\"\n  ) +\n  scale_fill_manual(labels = c(\"사실적 시나리오\", \"첫 번째 개입만\", \"개입 없음\"), values = c(\"lightgreen\", \"lightblue\", \"pink\")) +\n  scale_color_manual(labels = c(\"사실적 시나리오\", \"첫 번째 개입만\", \"개입 없음\"), values = c(\"black\", \"blue\", \"red\"))\n\n\n\n\n\n\n\n\n위 그래프에서 검은색 실선(녹색 리본)은 실제 데이터와 두 번의 개입을 모두 고려한 모델의 예측값입니다. 붉은색 점선(분홍색 리본)은 어떠한 개입도 없었다고 가정한 반사실적 시나리오의 예측값이며, 파란색 점선(하늘색 리본)은 첫 번째 개입만 있었다고 가정한 반사실적 시나리오의 예측값입니다.\n각 시점에서 사실적 시나리오와 반사실적 시나리오의 차이를 통해 각 개입의 효과를 정량적으로 평가할 수 있습니다. 예를 들어, 150주차에서 사실적 시나리오 값과 첫 번째 반사실적 시나리오 값을 비교하면 두 번째 개입의 순수한 효과를 추정할 수 있습니다.\n\n\n5.4.3 개입 효과 크기 계산 (두 번의 개입):\n저장된 모델 예측값을 사용하여 특정 시점에서 각 개입의 상대적인 효과를 계산할 수 있습니다.\n\n# 첫 번째 개입 직후 효과 (51주차):\nformat(df3$model.d.predictions[51] - df3$model.e.predictions[51], scientific = F)\n\n        51 \n\"6.092123\" \n\n# 두 번째 개입 직후 효과 (101주차):\nformat(df3$model.d.predictions[101] - df3$model.f.predictions[101], scientific = F)\n\n        101 \n\"-6.791491\" \n\n# 연구 종료 시점의 전체 개입 효과 (150주차):\nformat(df3$model.d.predictions[150] - df3$model.e.predictions[150], scientific = F)\n\n       150 \n\"50.90872\" \n\n\n결과 해석 시에는 산업보건 맥락을 고려하여 각 개입의 성격과 예상되는 효과를 바탕으로 논리적인 설명을 제시해야 합니다. 또한, 모델의 가정(예: 선형 추세, 개입 효과의 지속성 등)이 실제 데이터에 부합하는지 신중하게 평가해야 합니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>중단된 시계열 분석</span>"
    ]
  },
  {
    "objectID": "InterruptedTS.html#파트-3-통제된-its-단일-개입",
    "href": "InterruptedTS.html#파트-3-통제된-its-단일-개입",
    "title": "5  중단된 시계열 분석",
    "section": "5.5 파트 3: 통제된 ITS, 단일 개입",
    "text": "5.5 파트 3: 통제된 ITS, 단일 개입\n이전까지는 통제 그룹 없이 단일 시계열 데이터만 분석하는 방법을 살펴보았습니다. 이제 통제 그룹을 포함하는 통제된 ITS 분석을 통해 개입의 효과를 보다 정확하게 평가하는 방법을 알아보겠습니다.\n가상 데이터 생성 (통제 그룹 포함):\n다음은 통제 그룹(quantity.y)과 개입 그룹(quantity.x)을 포함하는 가상 데이터를 생성하는 R 코드입니다\n\nlibrary(tidyverse)\nlibrary(nlme)\nlibrary(AICcmodavg)\nlibrary(DT)\n\n# 개입 시점: 51주차\ndf.x &lt;- tibble(\n  x = 1, # 개입 그룹 (x = 1)\n  Time = 1:100,\n  x.Time = x * Time, # Time 변수와 개입 그룹의 상호작용\n  Intervention = c(rep(0, 50), rep(1, 50)),\n  x.Intervention = x * Intervention, # Intervention 변수와 개입 그룹의 상호작용\n  Post.intervention.time = c(rep(0, 50), 1:50),\n  x.Post.intervention.time = x * Post.intervention.time, # Post.intervention.time 변수와 개입 그룹의 상호작용\n  quantity.x = c(sort(sample(200:300, size = 50, replace = T), decreasing = T) + sample(-20:20, 50, replace = T),\n                 c(sort(sample(20:170, size = 50, replace = T), decreasing = T) + sample(-40:40, 50, replace = T)))\n)\n\ndf.y &lt;- tibble(\n  x = 0, # 통제 그룹 (x = 0)\n  Time = 1:100,\n  x.Time = x * Time,\n  Intervention = c(rep(0, 50), rep(1, 50)),\n  x.Intervention = x * Intervention,\n  Post.intervention.time = c(rep(0, 50), 1:50),\n  x.Post.intervention.time = x * Post.intervention.time,\n  quantity.x = c(sort(sample(500:600, size = 50, replace = T), decreasing = T) + sample(-20:20, 50, replace = T),\n                 c(sort(sample(280:500, size = 50, replace = T), decreasing = T) + sample(-40:40, 50, replace = T)))\n)\n\ndf6 &lt;- bind_rows(df.x, df.y) %&gt;%\n  arrange(Time, x)\n\ndatatable(df6, options = list(pageLength = 200, scrollY = \"200px\"))\n\n\n\n\n\n위 코드는 다음과 같은 변수를 포함하는 데이터 프레임을 생성합니다.\n\nx: 그룹을 구분하는 변수 (0: 통제 그룹, 1: 개입 그룹).\nTime: 연구가 진행된 주차.\nx.Time: Time 변수와 x 변수의 상호작용 항.\nIntervention: 개입 여부 (0: 개입 전, 1: 개입 후).\nx.Intervention: Intervention 변수와 x 변수의 상호작용 항.\nPost.intervention.time: 개입 후 경과 시간.\nx.Post.intervention.time: Post.intervention.time 변수와 x 변수의 상호작용 항.\nquantity.x: 결과 변수 (산업재해 발생 건수).\n\n\n5.5.1 통제된 ITS 모델 구축:\n통제 그룹을 포함한 ITS 모델은 다음과 같이 구축할 수 있습니다.\n\nmodel.g &lt;- gls(quantity.x ~ x + Time + x.Time + Intervention + x.Intervention + Post.intervention.time + x.Post.intervention.time,\n               data = df6, method = \"ML\", correlation = corARMA(p = 2, q = 2, form = ~ Time | x))\nsummary(model.g)\n\nGeneralized least squares fit by maximum likelihood\n  Model: quantity.x ~ x + Time + x.Time + Intervention + x.Intervention +      Post.intervention.time + x.Post.intervention.time \n  Data: df6 \n       AIC      BIC    logLik\n  1740.045 1782.923 -857.0226\n\nCorrelation Structure: ARMA(2,2)\n Formula: ~Time | x \n Parameter estimate(s):\n         Phi1          Phi2        Theta1        Theta2 \n-1.177446e-01  8.391505e-01 -9.056629e-06 -9.999909e-01 \n\nCoefficients:\n                             Value Std.Error   t-value p-value\n(Intercept)               605.5333  2.911587 207.97365  0.0000\nx                        -305.5079  4.117605 -74.19553  0.0000\nTime                       -2.0115  0.107664 -18.68307  0.0000\nx.Time                      0.0734  0.152260   0.48220  0.6302\nIntervention               -5.7824  4.841184  -1.19442  0.2338\nx.Intervention            -11.5796  6.846467  -1.69132  0.0924\nPost.intervention.time     -1.5456  0.129083 -11.97404  0.0000\nx.Post.intervention.time   -0.0831  0.182551  -0.45494  0.6497\n\n Correlation: \n                         (Intr) x      Time   x.Time Intrvn x.Intr Pst.n.\nx                        -0.707                                          \nTime                     -0.956  0.676                                   \nx.Time                    0.676 -0.956 -0.707                            \nIntervention              0.590 -0.417 -0.758  0.536                     \nx.Intervention           -0.417  0.590  0.536 -0.758 -0.707              \nPost.intervention.time    0.661 -0.467 -0.599  0.424 -0.013  0.009       \nx.Post.intervention.time -0.467  0.661  0.424 -0.599  0.009 -0.013 -0.707\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.9007854 -0.6478441  0.1184057  0.6977688  1.9536951 \n\nResidual standard error: 18.05594 \nDegrees of freedom: 200 total; 192 residual\n\n\ncorARMA 함수의 form = ~ Time | x 인수는 자기상관을 시간뿐만 아니라 그룹 간에도 고려하도록 지정합니다.\n\n모델 결과 해석:\n\n모델 결과의 계수는 다음과 같이 해석할 수 있습니다.\n\n(Intercept): 통제 그룹의 연구 시작 시점의 평균 결과 변수 값.\nx: 개입 그룹과 통제 그룹 간의 연구 시작 시점의 평균 결과 변수 값 차이.\nTime: 통제 그룹의 개입 전 시간 추세.\nx.Time: 개입 그룹과 통제 그룹 간의 개입 전 시간 추세 차이.\nIntervention: 통제 그룹의 개입 시점에서의 즉각적인 단계 변화.\nx.Intervention: 개입 그룹과 통제 그룹 간의 개입 시점에서의 즉각적인 단계 변화 * 차이.\nPost.intervention.time: 통제 그룹의 개입 이후 시간 추세 변화.\nx.Post.intervention.time: 개입 그룹과 통제 그룹 간의 개입 이후 시간 추세 변화 차이.\n\n\n\n5.5.2 대안적인 모델 구축 (상호작용 항 사용):\n상호작용 항을 사용하여 동일한 결과를 얻을 수 있습니다.\n\nmodel.h &lt;- gls(quantity.x ~ Time * x + Intervention * x + Post.intervention.time * x,\n               data = df6, method = \"ML\", correlation = corARMA(p = 2, q = 2, form = ~ Time | x))\nsummary(model.h)\n\nGeneralized least squares fit by maximum likelihood\n  Model: quantity.x ~ Time * x + Intervention * x + Post.intervention.time *      x \n  Data: df6 \n       AIC      BIC    logLik\n  1740.045 1782.923 -857.0226\n\nCorrelation Structure: ARMA(2,2)\n Formula: ~Time | x \n Parameter estimate(s):\n         Phi1          Phi2        Theta1        Theta2 \n-1.177446e-01  8.391505e-01 -9.017984e-06 -9.999910e-01 \n\nCoefficients:\n                             Value Std.Error   t-value p-value\n(Intercept)               605.5333  2.911587 207.97365  0.0000\nTime                       -2.0115  0.107664 -18.68307  0.0000\nx                        -305.5079  4.117605 -74.19553  0.0000\nIntervention               -5.7824  4.841184  -1.19442  0.2338\nPost.intervention.time     -1.5456  0.129083 -11.97404  0.0000\nTime:x                      0.0734  0.152260   0.48220  0.6302\nx:Intervention            -11.5796  6.846467  -1.69132  0.0924\nx:Post.intervention.time   -0.0831  0.182551  -0.45494  0.6497\n\n Correlation: \n                         (Intr) Time   x      Intrvn Pst.n. Time:x x:Intr\nTime                     -0.956                                          \nx                        -0.707  0.676                                   \nIntervention              0.590 -0.758 -0.417                            \nPost.intervention.time    0.661 -0.599 -0.467 -0.013                     \nTime:x                    0.676 -0.707 -0.956  0.536  0.424              \nx:Intervention           -0.417  0.536  0.590 -0.707  0.009 -0.758       \nx:Post.intervention.time -0.467  0.424  0.661  0.009 -0.707 -0.599 -0.013\n\nStandardized residuals:\n       Min         Q1        Med         Q3        Max \n-2.9007854 -0.6478441  0.1184057  0.6977688  1.9536951 \n\nResidual standard error: 18.05594 \nDegrees of freedom: 200 total; 192 residual\n\n\nmodel.g와 model.h는 동일한 결과를 제공하지만, 계수 해석 방식이 다릅니다.\n\n모델 예측값 및 시각화:\n\n\ndf6 &lt;- df6 %&gt;% mutate(\n  model.g.predictions = predictSE.gls(model.g, df6, se.fit = T)$fit,\n  model.g.se = predictSE.gls(model.g, df6, se.fit = T)$se\n)\n\nggplot(df6, aes(Time, quantity.x)) +\n  geom_point(color = \"grey\") +\n  geom_ribbon(aes(ymin = model.g.predictions - (1.96 * model.g.se), ymax = model.g.predictions + (1.96 * model.g.se), fill = factor(x), alpha = 0.4)) +\n  geom_line(aes(Time, model.g.predictions, color = factor(x)), lty = 1) +\n  geom_point(alpha = 0.3) +\n  labs(\n    title = \"통제된 ITS 분석\",\n    x = \"주차\",\n    y = \"주간 산업재해 발생 건수\",\n    color = \"그룹\",\n    fill = \"그룹\"\n  ) +\n  scale_color_manual(labels = c(\"통제 그룹\", \"개입 그룹\"), values = c(\"black\", \"red\")) +\n  scale_fill_manual(labels = c(\"통제 그룹\", \"개입 그룹\"), values = c(\"black\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n5.5.3 반사실적 시나리오 분석:\n개입이 없었다면 어떤 일이 발생했을지를 추정하기 위해 반사실적 모델을 구축합니다.\n\ndf7 &lt;- filter(df6, Time &lt; 51)\nmodel.i &lt;- gls(quantity.x ~ x + Time + x.Time,\n               data = df7, correlation = corARMA(p = 1, q = 1, form = ~ Time | x), method = \"ML\")\n\ndf6 &lt;- df6 %&gt;% mutate(\n  model.i.predictions = predictSE.gls(model.i, newdata = df6, se.fit = T)$fit,\n  model.i.se = predictSE.gls(model.i, df6, se.fit = T)$se\n)\n\n사실적 모델과 반사실적 모델 비교 시각화:\n\nggplot(df6, aes(Time, quantity.x)) +\n  geom_point(color = \"grey\") +\n  geom_ribbon(aes(ymin = model.g.predictions - (1.96 * model.g.se), ymax = model.g.predictions + (1.96 * model.g.se), fill = factor(x), alpha = 0.4)) +\n  geom_line(aes(Time, model.g.predictions, color = factor(x)), lty = 1) +\n  geom_line(aes(Time, model.i.predictions, color = factor(x)), lty = 2) +\n  geom_ribbon(aes(ymin = model.i.predictions - (1.96 * model.i.se), ymax = model.i.predictions + (1.96 * model.i.se), fill = factor(x), alpha = 0.2)) +\n  labs(\n    title = \"통제된 ITS 분석: 사실적 vs. 반사실적 시나리오\",\n    x = \"주차\",\n    y = \"주간 산업재해 발생 건수\",\n    color = \"그룹\",\n    fill = \"그룹\"\n  ) +\n  scale_color_manual(labels = c(\"통제 그룹\", \"개입 그룹\"), values = c(\"black\", \"red\")) +\n  scale_fill_manual(labels = c(\"통제 그룹\", \"개입 그룹\"), values = c(\"black\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n5.5.4 통제 그룹의 효과 평가:\n통제 그룹이 분석 결과에 미치는 영향을 평가하기 위해, 통제 그룹을 포함한 모델(model.g)과 포함하지 않은 모델(model.j)의 결과를 비교합니다.\n\n# 통제 그룹을 포함하지 않은 모델\nmodel.j = gls(quantity.x ~ Time + Intervention  + Post.intervention.time , data = df.x,method=\"ML\", correlation= corARMA(p=2,q=2, form = ~ Time))\ndf.x &lt;- df.x %&gt;%\n  mutate(\n    model.j.predictions = predictSE.gls(model.j, newdata = df.x, se.fit = T)$fit,\n    model.j.se = predictSE.gls(model.j, df.x, se.fit = T)$se\n  )\n\ndf8 &lt;- filter(df.x, Time &lt; 51)\n\nmodel.k &lt;- gls(quantity.x ~ Time, data = df8, correlation = corARMA(p = 1, q = 1, form = ~ Time), method = \"ML\")\n\ndf.x &lt;- df.x %&gt;%\n  mutate(\n    model.k.predictions = predictSE.gls(model.k, newdata = df.x, se.fit = T)$fit,\n    model.k.se = predictSE.gls(model.k, df.x, se.fit = T)$se\n  )\n\n# 통제 그룹을 포함한 모델과 포함하지 않은 모델의 결과 비교\ndf6$model.g.predictions[200] - df6$model.i.predictions[200] # 통제 그룹 포함 모델\n\n      200 \n-97.61419 \n\ndf.x$model.j.predictions[100] - df.x$model.k.predictions[100] # 통제 그룹 미포함 모델\n\n      100 \n-95.74245 \n\n\n\n통제 그룹 포함 모델의 개입 효과 추정치: 약 -60.99\n통제 그룹 미포함 모델의 개입 효과 추정치: 약 -61.25\n\n이 코드를 통해 통제 그룹을 포함했을 때와 포함하지 않았을 때의 개입 효과 추정치를 비교하고, 통제 그룹이 분석 결과에 미치는 영향을 평가할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>중단된 시계열 분석</span>"
    ]
  },
  {
    "objectID": "Jobstress.html",
    "href": "Jobstress.html",
    "title": "6  job stress questionnaires",
    "section": "",
    "text": "6.1 설문지 개발\n본 강의에서는 2014년 장세진 등이 연구한 한국형 감정노동 설문지의 연구 계발 중 감정노동 설문지 하부 구조 구성에 대한 내용입니다. 감정근로자를 대상으로한 질적 면담을 통해 총 26개 질적 항목이 도출되었고, 이를 조사 문항으로 변경하였고, 2014년 약 2000명의 고객 응대 근로자를 조사하였다. 이 중 변수를 축소할 수 있으지, 불필요한 변수가 있는지, 변수 사이에 일정한 특성이 있어 하부 구조를 만들수 있는지 여부를 판단하는 것이 실습 목표입니다.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>job stress questionnaires</span>"
    ]
  },
  {
    "objectID": "Jobstress.html#설문지-개발",
    "href": "Jobstress.html#설문지-개발",
    "title": "6  job stress questionnaires",
    "section": "",
    "text": "6.1.1 기본 R 준비\ntidyverse 를 통해 대부분의 data step 과정을 수행할 것이며, 라벨 작업을 위해 labelled package를 이용할 것이다. spss 파일을 불러오기위해 haven package 사용할 것이다.\n\nlibrary(tidyverse)\nlibrary(labelled)\nlibrary(haven)\n\n\n\n6.1.2 basic data step\nspss 파일인 data_n2221.sav를 불러 dat에 저장한다. 이후 처음부터 100번째 줄만 사용한다.\n\nurl &lt;- \"https://raw.githubusercontent.com/jinhaslab/opendata/main/data/data_n2221.sav\"\ndownload.file(url, \"data/jobstress/data_n2221.sav\")\nurl2 &lt;- \"https://raw.githubusercontent.com/jinhaslab/opendata/main/data/lookup.RData\"\ndownload.file(url2, \"data/jobstress/lookup.RData\")\n\n\ndat&lt;-read_sav(\"data/jobstress/data_n2221.sav\")\ndat &lt;-dat[, 1:100 ]\n\n\nlook_for(dat, details = FALSE) %&gt;% DT::datatable()\n\n\n\n\n\n\n\n6.1.3 설문지와 데이터 비교하기\n설문지를 찾아보면 아래와 같이 감정노동 설문지가 있다. a1부터 a26까지 라밸을 붙여 기억하기 쉽게 하자.\n\n\n\n감정노동설문지\n\n\n\n\n6.1.4 변수에 라벨링 붙이기\na1 ~ a6 까지의 변수에 emotional labor Q를 1부터 26까지 라벨로 저장해보자. 참고로 레이블은 변수에 list 처럼 정보가 저장되어 변수별 list를 만들고 즉, an[1]에 emotional labor Q1을 저장하고 반복하면 된다.\n\nan &lt;- list()\nfor (i in 1:26) {an[i] &lt;- paste('emotional labor Q', i, sep=\"\")}\nnames(an) &lt;- paste('a', 1:26, sep=\"\")\nvar_label(dat) &lt;- an\nlook_for(dat) %&gt;% DT::datatable()\n\n\n\n\n\nb1… c1.. .변수는 고객 폭력 설문지이다. 따라서 이번 실습에서는 사용하지 않도록 하겠다. 시작이 b 또는 c로 시작되고 뒤에 숫자가 붙어 있는 변수는 모두 제거하려고 한다. (^는 맨 앞이란 뜻, \\\\d는 )\n\ndat2 &lt;- dat %&gt;% select(!grep('^b|c\\\\d', names(dat)))\n\n\n\n6.1.5 결측값 제거\n감정노동 설문지에서 결측값이 있는 경우 실습에서 제외 하도록 하자. 이제 분석을 위해 gg 라는 파일을 만들자 시작이 a이고 뒤에 숫자가 붙어 있는 변수는 감정노동 변수이다. 이때 NA가 포함되어 있는 것은 모두 지우고자 한다.\n\ngg&lt;-dat2 %&gt;% drop_na(grep('^a\\\\d', names(dat2)))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>job stress questionnaires</span>"
    ]
  },
  {
    "objectID": "Jobstress.html#주성분분석",
    "href": "Jobstress.html#주성분분석",
    "title": "6  job stress questionnaires",
    "section": "6.2 주성분분석",
    "text": "6.2 주성분분석\n\n6.2.1 주성분분석 간단 소개\n주성분분석을 간단히 설명하면, 잠재적으로 적은 수의 관찰되지 않은 변수의 관점에서 관찰 된 상관 변수 간의 변동성을 설명하고자 하는 방법이다. 이때 잠재적으로 적은 수의 관찰되지 않은 변수가 요인(factor)가 된다-wikipedia. 즉 현재 26개의 감정노동 변수가 몇개의 요인으로 설명될수 있는지를 물어보자. 만약 2개의 요인 감정의 피로, 조직의 보호 같은 요인이 숨어 있다고 해보자. 그리고 2개의 요인이 전체 데이터를 한 70% 설명해 준다고 하자. 그러면 2개의 요인의 요약값으로 데이터를 해석하고 분석하는 것도 매우 효율적인 방법 중 하나일 것이다. 이렇게 되면 어떠한 설문문항은 감정의 피로는 높고 조직의 보호는 낮은 것으로 이해되고, 어떠한 설문문항은 감정의 피로도 높고 조직의 보호도 높은 것일 수 있다. 즉 \\(X_1, X_2 . . .X_N\\)의 변수는 요인(\\(F_k\\))(unobservable latent factors)로 인해 설명될 수 있다. 즉, \\[ X_1 = w_{1,0} + w_{1,1}F_1 ...w_{1,k}F_k + e_1 \\\\\n   X_2 = w_{2,0} + w_{2,1}F_1 ...w_{2,k}F_k + e_2 \\\\\n   ..... \\\\\n   X_N = w_{N,0} + w_{N,1}F_1 ...w_{N,k}F_k + e_N \\\\\n\\] 여기서 \\(k\\)가 얼마일지에 대한 대답을 하는 과정 이기도 하다.\n\n\n6.2.2 요인이 몇개면 좋을까?\n설문지 항목을 읽어보고 몇개로 나누면 좋을지 생각해보자. 아까의 설문지 파일을 다시 보자.\n\n\n\n\n\n\n\n\n\nvariable\nQuestionnaire\n\n\n\n\na1\n1. 고객에게 부정적인 감정을 표현하지 않으려고 의식적으로 노력한다.\n\n\na2\n2. 고객을 대할 때 회사의 요구대로 감정 표현을 할 수밖에 없다.\n\n\na3\n3. 업무상 고객을 대하는 과정에서 나의 솔직한 감정을 숨긴다.\n\n\na4\n4. 일상적인 업무수행을 위해서는 감정을 조절하려는 노력이 필요하다.\n\n\na5\n5. 고객을 대할 때 느끼는 나의 감정과 내가 실제 표현하는 감정은 다르다.\n\n\na6\n6. 공격적이거나 까다로운 고객을 상대해야 한다.\n\n\na7\n7. 나의 능력이나 권한 밖의 일을 요구하는 고객을 상대해야 한다.\n\n\na8\n8. 고객의 부당하거나 막무가내의 요구로 업무 수행의 어려움이 있다.\n\n\na9\n9. 직장은 나의 상황보다는 고객의 입장만을 고려하도록 강요한다.\n\n\na10\n10. 고객을 응대할 때 자존심이 상한다.\n\n\na11\n11. 고객에게 감정을 숨기고 표현하지 못할 때 나는 감정이 상한다.\n\n\na12\n12. 고객을 응대할 때 나의 감정이 상품처럼 느껴진다.\n\n\na13\n13. 퇴근 후에도 고객을 응대할 때 힘들었던 감정이 남아 있다.\n\n\na14\n14. 고객을 대하는 과정에서 마음의 상처를 받는다.\n\n\na15\n15. 몸이 피곤해도 고객들에게 최선을 다해야 하므로 감정적으로 힘들다.\n\n\na16\n16. 직장이 요구하는 대로 고객에게 잘 응대하는지 감시를 당한다(CC TV 등).\n\n\na17\n17. 고객의 평가가 업무성과평가나 인사고과에 영향을 준다.\n\n\na18\n18. 고객 응대에 문제가 발생했을 때, 나의 잘못이 아닌데도 직장으로부터 부당한 처우를 받는다.\n\n\na19\n19. 직원들을 보호하기 위하여 고객들의 부당한 행위를 직장에서 모니터링(관찰, 녹음, 확인 등) 하고 있다.\n\n\na20\n20. 고객 응대 과정에서 문제가 발생 시 직장에서 적절한 조치가 이루어진다.\n\n\na21\n21. 고객 응대 과정에서 발생한 문제를 해결하고 도와주는 직장 내의 공식적인 제도와 절차가 있다.\n\n\na22\n22. 직장은 고객 응대 과정에서 입은 마음의 상처를 위로받게 해준다.\n\n\na23\n23. 상사는 고객 응대 과정에서 발생한 문제를 해결하기 위해 도와준다.\n\n\na24\n24. 동료는 고객 응대 과정에서 발생한 문제를 해결하기 위해 도와준다.\n\n\na25\n25. 직장 내에 고객 응대에 관한 행동지침이나 매뉴얼(설명서, 안내서)이 마련되어 있다.\n\n\na26\n26. 고객의 요구를 해결해 줄 수 있는 권한이나 자율성이 나에게 주어져 있다.\n\n\n\n\n\nPCA (principal Components Anaysis)를 실행해 보자. 우선 분석 데이터의 이름을 gg로 바꾸었고, 이중 PCA를 돌릴 감정노동 변수만을 em으로 선정하자.\n\nem &lt;-gg %&gt;% select(grep('^a\\\\d', names(gg)))\nfit &lt;-princomp(em, cor=TRUE)\nsummary(fit)\n\nImportance of components:\n                          Comp.1    Comp.2     Comp.3     Comp.4    Comp.5\nStandard deviation     2.9109785 1.8140133 1.29145144 1.14149754 0.9981856\nProportion of Variance 0.3259152 0.1265632 0.06414796 0.05011602 0.0383221\nCumulative Proportion  0.3259152 0.4524785 0.51662643 0.56674246 0.6050646\n                           Comp.6     Comp.7     Comp.8     Comp.9    Comp.10\nStandard deviation     0.94878939 0.88188337 0.85890832 0.82933490 0.80598461\nProportion of Variance 0.03462313 0.02991224 0.02837398 0.02645371 0.02498505\nCumulative Proportion  0.63968768 0.66959992 0.69797390 0.72442761 0.74941266\n                          Comp.11    Comp.12    Comp.13    Comp.14    Comp.15\nStandard deviation     0.76934437 0.75306547 0.71665409 0.70291372 0.70214574\nProportion of Variance 0.02276503 0.02181183 0.01975358 0.01900337 0.01896187\nCumulative Proportion  0.77217769 0.79398952 0.81374310 0.83274647 0.85170834\n                          Comp.16    Comp.17    Comp.18    Comp.19    Comp.20\nStandard deviation     0.67203301 0.65055854 0.64059641 0.62269499 0.61420308\nProportion of Variance 0.01737032 0.01627794 0.01578322 0.01491343 0.01450944\nCumulative Proportion  0.86907866 0.88535660 0.90113982 0.91605325 0.93056269\n                         Comp.21    Comp.22    Comp.23    Comp.24     Comp.25\nStandard deviation     0.5965547 0.58295100 0.56112051 0.55494148 0.501662398\nProportion of Variance 0.0136876 0.01307046 0.01210985 0.01184462 0.009679429\nCumulative Proportion  0.9442503 0.95732074 0.96943059 0.98127521 0.990954641\n                           Comp.26\nStandard deviation     0.484952908\nProportion of Variance 0.009045359\nCumulative Proportion  1.000000000\n\n\n그림을 그려보자\n\nplot(fit, type=\"lines\")\nabline(h=1, col=\"blue\")\n\n\n\n\n\n\n\n\n\n6.2.2.1 library nFactors 이용하기\n\nlibrary(nFactors)\nev &lt;- eigen(cor(em)) # get eigenvalues\nap &lt;- parallel(subject=nrow(em),var=ncol(em),rep=100,cent=.05)\nnS &lt;- nScree(x=ev$values, aparallel=ap$eigen$qevpea)\nplotnScree(nS)\n\n\n\n\n\n\n\n\n요인의 개수를 4개 또는 5개로 추천해 주고 있다. 여튼 4개 이상의 요인 구성해보고 시작해보자.\n\n\n\n6.2.3 요인 고정 분석\n\nlibrary(psych)\nfit &lt;- principal(em, nfactors=4, rotate=\"varimax\")\n#print(fit, digits = 3, sort = TRUE)\n\n로딩값 0.4이상인 것을 하나의 동일한 요인으로 구분해보고, 우리의 생각과 비슷한지 관찰해 보자.\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ\nques\nRC1\nRC2\nRC3\nRC4\n\n\n\n\na14\n14. 고객을 대하는 과정에서 마음의 상처를 받는다.\n0.823\n-0.067\n0.107\n0.129\n\n\na13\n13. 퇴근 후에도 고객을 응대할 때 힘들었던 감정이 남아 있다.\n0.785\n-0.074\n0.078\n0.109\n\n\na11\n11. 고객에게 감정을 숨기고 표현하지 못할 때 나는 감정이 상한다.\n0.756\n-0.077\n0.175\n0.134\n\n\na10\n10. 고객을 응대할 때 자존심이 상한다.\n0.754\n-0.146\n0.166\n0.190\n\n\na12\n12. 고객을 응대할 때 나의 감정이 상품처럼 느껴진다.\n0.741\n-0.110\n0.146\n0.195\n\n\na15\n15. 몸이 피곤해도 고객들에게 최선을 다해야 하므로 감정적으로 힘들다.\n0.726\n-0.064\n0.242\n0.162\n\n\na8\n8. 고객의 부당하거나 막무가내의 요구로 업무 수행의 어려움이 있다.\n0.680\n-0.083\n0.335\n0.161\n\n\na7\n7. 나의 능력이나 권한 밖의 일을 요구하는 고객을 상대해야 한다.\n0.634\n-0.086\n0.366\n0.102\n\n\na6\n6. 공격적이거나 까다로운 고객을 상대해야 한다.\n0.598\n-0.025\n0.426\n0.054\n\n\na9\n9. 직장은 나의 상황보다는 고객의 입장만을 고려하도록 강요한다.\n0.544\n-0.201\n0.304\n0.321\n\n\na23\n23. 상사는 고객 응대 과정에서 발생한 문제를 해결하기 위해 도와준다.\n-0.114\n0.775\n0.022\n-0.099\n\n\na21\n21. 고객 응대 과정에서 발생한 문제를 해결하고 도와주는 직장 내의 공식적인 제도와 절차가 있다.\n-0.136\n0.764\n-0.002\n0.132\n\n\na20\n20. 고객 응대 과정에서 문제가 발생 시 직장에서 적절한 조치가 이루어진다.\n-0.109\n0.715\n0.046\n0.146\n\n\na22\n22. 직장은 고객 응대 과정에서 입은 마음의 상처를 위로받게 해준다.\n-0.196\n0.706\n-0.174\n-0.089\n\n\na25\n25. 직장 내에 고객 응대에 관한 행동지침이나 매뉴얼(설명서, 안내서)이 마련되어 있다.\n-0.069\n0.609\n0.101\n0.129\n\n\na24\n24. 동료는 고객 응대 과정에서 발생한 문제를 해결하기 위해 도와준다.\n0.069\n0.581\n0.079\n-0.137\n\n\na26\n26. 고객의 요구를 해결해 줄 수 있는 권한이나 자율성이 나에게 주어져 있다.\n-0.055\n0.575\n-0.159\n-0.191\n\n\na3\n3. 업무상 고객을 대하는 과정에서 나의 솔직한 감정을 숨긴다.\n0.209\n-0.031\n0.769\n0.075\n\n\na1\n1. 고객에게 부정적인 감정을 표현하지 않으려고 의식적으로 노력한다.\n0.146\n0.060\n0.729\n0.069\n\n\na2\n2. 고객을 대할 때 회사의 요구대로 감정 표현을 할 수밖에 없다.\n0.225\n-0.017\n0.664\n0.207\n\n\na4\n4. 일상적인 업무수행을 위해서는 감정을 조절하려는 노력이 필요하다.\n0.235\n0.051\n0.664\n-0.017\n\n\na5\n5. 고객을 대할 때 느끼는 나의 감정과 내가 실제 표현하는 감정은 다르다.\n0.426\n-0.056\n0.574\n0.054\n\n\na16\n16. 직장이 요구하는 대로 고객에게 잘 응대하는지 감시를 당한다(CC TV 등).\n0.307\n-0.136\n0.084\n0.707\n\n\na19\n19. 직원들을 보호하기 위하여 고객들의 부당한 행위를 직장에서 모니터링(관찰, 녹음, 확인 등) 하고 있다.\n0.076\n0.301\n-0.005\n0.666\n\n\na17\n17. 고객의 평가가 업무성과평가나 인사고과에 영향을 준다.\n0.338\n-0.034\n0.211\n0.656\n\n\na18\n18. 고객 응대에 문제가 발생했을 때, 나의 잘못이 아닌데도 직장으로부터 부당한 처우를 받는다.\n0.406\n-0.268\n0.131\n0.588\n\n\n\n\n\n\nlibrary(psych)\nfit5 &lt;- principal(em, nfactors=5, rotate=\"varimax\")\n#print(fit5, digits = 3, sort = TRUE)\n\n로딩값 0.4이상인 것을 하나의 동일한 요인으로 구분해보고, 우리의 생각과 비슷한지 관찰해 보자.\n\n\n\n\n\nQ\nques\nRC1\nRC2\nRC3\nRC4\nRC5\n\n\n\n\na14\n14. 고객을 대하는 과정에서 마음의 상처를 받는다.\n0.833\n-0.080\n0.160\n0.142\n0.129\n\n\na13\n13. 퇴근 후에도 고객을 응대할 때 힘들었던 감정이 남아 있다.\n0.793\n-0.086\n0.126\n0.122\n0.130\n\n\na11\n11. 고객에게 감정을 숨기고 표현하지 못할 때 나는 감정이 상한다.\n0.758\n-0.089\n0.222\n0.147\n0.134\n\n\na12\n12. 고객을 응대할 때 나의 감정이 상품처럼 느껴진다.\n0.743\n-0.121\n0.192\n0.207\n0.124\n\n\na10\n10. 고객을 응대할 때 자존심이 상한다.\n0.714\n-0.153\n0.187\n0.211\n0.225\n\n\na15\n15. 몸이 피곤해도 고객들에게 최선을 다해야 하므로 감정적으로 힘들다.\n0.693\n-0.072\n0.268\n0.180\n0.207\n\n\na9\n9. 직장은 나의 상황보다는 고객의 입장만을 고려하도록 강요한다.\n0.418\n-0.196\n0.265\n0.354\n0.376\n\n\na23\n23. 상사는 고객 응대 과정에서 발생한 문제를 해결하기 위해 도와준다.\n-0.101\n0.775\n0.026\n-0.108\n-0.039\n\n\na21\n21. 고객 응대 과정에서 발생한 문제를 해결하고 도와주는 직장 내의 공식적인 제도와 절차가 있다.\n-0.095\n0.763\n0.021\n0.116\n-0.130\n\n\na20\n20. 고객 응대 과정에서 문제가 발생 시 직장에서 적절한 조치가 이루어진다.\n-0.022\n0.708\n0.100\n0.121\n-0.234\n\n\na22\n22. 직장은 고객 응대 과정에서 입은 마음의 상처를 위로받게 해준다.\n-0.112\n0.701\n-0.136\n-0.112\n-0.223\n\n\na25\n25. 직장 내에 고객 응대에 관한 행동지침이나 매뉴얼(설명서, 안내서)이 마련되어 있다.\n-0.128\n0.617\n0.067\n0.135\n0.119\n\n\na24\n24. 동료는 고객 응대 과정에서 발생한 문제를 해결하기 위해 도와준다.\n-0.025\n0.590\n0.026\n-0.121\n0.252\n\n\na26\n26. 고객의 요구를 해결해 줄 수 있는 권한이나 자율성이 나에게 주어져 있다.\n-0.058\n0.578\n-0.169\n-0.192\n0.020\n\n\na3\n3. 업무상 고객을 대하는 과정에서 나의 솔직한 감정을 숨긴다.\n0.198\n-0.043\n0.797\n0.073\n0.059\n\n\na1\n1. 고객에게 부정적인 감정을 표현하지 않으려고 의식적으로 노력한다.\n0.120\n0.050\n0.743\n0.068\n0.082\n\n\na2\n2. 고객을 대할 때 회사의 요구대로 감정 표현을 할 수밖에 없다.\n0.194\n-0.026\n0.678\n0.210\n0.099\n\n\na4\n4. 일상적인 업무수행을 위해서는 감정을 조절하려는 노력이 필요하다.\n0.168\n0.046\n0.654\n-0.006\n0.205\n\n\na5\n5. 고객을 대할 때 느끼는 나의 감정과 내가 실제 표현하는 감정은 다르다.\n0.371\n-0.064\n0.579\n0.068\n0.210\n\n\na16\n16. 직장이 요구하는 대로 고객에게 잘 응대하는지 감시를 당한다(CC TV 등).\n0.252\n-0.130\n0.077\n0.721\n0.126\n\n\na17\n17. 고객의 평가가 업무성과평가나 인사고과에 영향을 준다.\n0.232\n-0.025\n0.176\n0.679\n0.257\n\n\na19\n19. 직원들을 보호하기 위하여 고객들의 부당한 행위를 직장에서 모니터링(관찰, 녹음, 확인 등) 하고 있다.\n0.121\n0.300\n0.036\n0.654\n-0.149\n\n\na18\n18. 고객 응대에 문제가 발생했을 때, 나의 잘못이 아닌데도 직장으로부터 부당한 처우를 받는다.\n0.318\n-0.261\n0.108\n0.611\n0.231\n\n\na7\n7. 나의 능력이나 권한 밖의 일을 요구하는 고객을 상대해야 한다.\n0.384\n-0.071\n0.254\n0.161\n0.705\n\n\na6\n6. 공격적이거나 까다로운 고객을 상대해야 한다.\n0.352\n-0.010\n0.317\n0.110\n0.693\n\n\na8\n8. 고객의 부당하거나 막무가내의 요구로 업무 수행의 어려움이 있다.\n0.459\n-0.071\n0.244\n0.215\n0.641",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>job stress questionnaires</span>"
    ]
  },
  {
    "objectID": "Jobstress.html#요인-개수-정하기-신뢰도-측면",
    "href": "Jobstress.html#요인-개수-정하기-신뢰도-측면",
    "title": "6  job stress questionnaires",
    "section": "6.3 요인 개수 정하기: 신뢰도 측면",
    "text": "6.3 요인 개수 정하기: 신뢰도 측면\n\n6.3.1 신뢰도 값 (Cronbach alpha)\n전체의 신뢰도 값은 `Cronbach alpha1를 구해보면\n\ntotal_alpha &lt;- em %&gt;% \n  alpha(check.keys = TRUE) %&gt;% summary() %&gt;% tibble() \n\n\nReliability analysis   \n raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n       0.9       0.9    0.93      0.26 9.2 0.0031  2.8 0.47     0.26\n\ntotal_alpha\n\n# A tibble: 0 × 0\n\n\n0.9로 매우 높다. 설문의 내적 신뢰도가 매우 높아 잘 구성된 설문으로 판단된다. 이와 마찬가지로, 각 5개 요인별 신뢰도를 구해서 비교해 보면 다음과 같다.\n\n\n[[1]]\n raw_alpha std.alpha   G6(smc) average_r      S/N         ase     mean\n 0.8999274 0.9018293 0.9295131 0.2610769 9.186341 0.003141005 2.827998\n        sd  median_r\n 0.4735525 0.2614902\n\n[[2]]\n raw_alpha std.alpha   G6(smc) average_r      S/N         ase    mean       sd\n 0.9055774 0.9057706 0.8991453 0.5786279 9.612397 0.003203386 2.89193 0.723457\n  median_r\n 0.5848336\n\n[[3]]\n raw_alpha std.alpha   G6(smc) average_r      S/N         ase     mean\n 0.8131309 0.8126849 0.8038001 0.3826398 4.338599 0.006332137 2.562161\n        sd  median_r\n 0.6179742 0.3435262\n\n[[4]]\n raw_alpha std.alpha   G6(smc) average_r      S/N        ase     mean        sd\n 0.7944449 0.7975002 0.7656453  0.440608 3.938276 0.00720726 3.381537 0.5348358\n  median_r\n 0.4384749\n\n[[5]]\n raw_alpha std.alpha   G6(smc) average_r      S/N        ase     mean        sd\n  0.715695 0.7199323 0.6839464 0.3912243 2.570565 0.01046568 2.481662 0.7527246\n  median_r\n 0.4126389\n\n[[6]]\n raw_alpha std.alpha   G6(smc) average_r      S/N        ase    mean        sd\n 0.8698312 0.8699297 0.8189101 0.6903434 6.688153 0.00501236 3.12841 0.7631397\n  median_r\n 0.6931711\n\n\n\n\n\nmodel\nraw_alpha\nstd.alpha\n\n\n\n\nTotal alpha\n0.900\n0.902\n\n\nRC1 alpha\n0.906\n0.906\n\n\nRC2 alpha\n0.813\n0.813\n\n\nRC3 alpha\n0.794\n0.798\n\n\nRC4 alpha\n0.716\n0.720\n\n\nRC5 alpha\n0.870\n0.870\n\n\n\n\n\n\n\n이후 연구잘들이 이렇게 모인 것이 의미적으로도 타당하고, 수치적으로도 타당하면 설문지로서 내적 신뢰도를 확보했다고 볼수 있다.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>job stress questionnaires</span>"
    ]
  },
  {
    "objectID": "Jobstress.html#요인값-활용하기",
    "href": "Jobstress.html#요인값-활용하기",
    "title": "6  job stress questionnaires",
    "section": "6.4 요인값 활용하기",
    "text": "6.4 요인값 활용하기\n\n6.4.1 요인값 데이터화\n요인값 (score)는 fit모델의 scores라는 list에 데이터 형식으로 저장되어 있다. 이를 gg 파일에 횡병합한다.\n\ngg1 &lt;- cbind(gg, fit5$scores)\nhead(gg1)\n\n  no_1 no_2 gender age education marriage                       job job_code\n1    3    1      2  34         3        1                    회사원        9\n2    3    2      2  27         3        1                 보상,상담        6\n3    3    3      2  37         3        2                    사무직        9\n4    3    4      2  40         2        2                    사무직        9\n5    3    5      2  44         1        2              가입지원요원        6\n6    3    6      2  38         3        2 근로복지공단 가입지원요원       12\n  job_code5 day_hour year month type shift working_hour holiday holiday_hour a1\n1         4        8   12     0    1     2           40       2           NA  4\n2         1        9    2     0    1     2           40       2           NA  3\n3         4        9   10     0    1     2           40       2           NA  4\n4         4        8   18     0    1     2           35       2           NA  4\n5         1        9    1     2    2     2           40       2           NA  4\n6         4        9    1     2    2     2           40       2           NA  3\n  a2 a3 a4 a5 a6 a7 a8 a9 a10 a11 a12 a13 a14 a15 a16 a17 a18 a19 a20 a21 a22\n1  4  4  4  4  4  3  4  3   3   4   3   4   4   4   3   2   1   2   3   3   2\n2  3  4  4  4  4  4  4  4   3   3   2   3   4   4   3   3   2   3   2   1   1\n3  4  4  4  4  4  3  3  3   3   4   3   3   3   3   2   3   4   2   1   3   2\n4  4  4  4  4  4  3  4  4   3   4   3   4   4   4   3   2   2   4   3   2   2\n5  1  3  4  3  4  2  2  3   3   3   3   3   3   2   1   1   1   1   1   1   2\n6  3  4  4  3  3  3  3  3   1   3   3   1   3   1   1   1   1   1   3   1   1\n  a23 a24 a25 a26 d1 d2 d3 d4 d5 d6 d7 d8 d9 e1 e2 e3 e4 e5 f1 f2 f3 g1 g1_day\n1   3   3   2   2  3  1  1  1  1  1  1  1  0  4  4  4  4  4  6  5  5  1     NA\n2   1   3   1   2  1  1  1  1  2  0  0  0  0  4  4  4  4  4  4  8  9  1     NA\n3   3   3   3   2  2  2  1  1  1  1  1  0  0  3  3  3  3  4  5 10  7  2     NA\n4   2   4   3   4  1  1  0  1  1  0  0  0  0  4  4  3  4  4  9 10 10  2     NA\n5   2   2   1   1  1  1  1  1  0  1  0  0  1  2  2  2  2  3  5  8  6  1     NA\n6   2   3   3   1  1  1  1  1  2  0  0  0  0  3  3  3  2  4  6  8  7  1     NA\n  g1_1 g2 g2_day g2_1 g3 g3_day g4 g5 g6 g6_1 age_group workhour new_month\n1   NA  1     NA   NA  2     NA  2  4  1   NA         2        2 0.0000000\n2   NA  1     NA   NA  2     NA  2  3  1   NA         1        2 0.0000000\n3    1  2     NA    1  2     NA  1  4  1   NA         2        2 0.0000000\n4    1  1     NA   NA  2     NA  2  3  1   NA         3        1 0.0000000\n5   NA  1     NA   NA  1     NA  2  2  1   NA         3        2 0.1666667\n6   NA  1     NA   NA  1     NA  2  3  1   NA         2        2 0.1666667\n   new_year         RC1        RC2         RC3        RC4         RC5\n1 12.000000  1.41391758  0.2697825  1.06493093 -1.2119756 -0.50045351\n2  2.000000  0.29155505 -1.3583095  0.06978903 -0.1336951  1.00758714\n3 10.000000  0.08621152 -0.2683814  1.02177770 -0.1138303  0.23768768\n4 18.000000  1.30583594  0.6955646  0.68449865 -0.3480365  0.07637027\n5  1.166667  0.49545461 -1.7340666 -0.31311884 -2.4465539 -0.62733016\n6  1.166667 -1.13527184 -1.0465152  0.72011247 -1.6794867  0.17207067\n\n\n\n\n6.4.2 우울증 점수 (PHQ-9)\nPHQ-9 설문지가 d1~d9까지있고, 우선 단순 합으로 계산한다(9번 문항의 별도 가중치 고려하지 않음).\n\ngg1 %&gt;%  select(grep('^d\\\\d', colnames(.))) %&gt;% \n         rowSums(.) -&gt; \ngg1$dep_score \n\n5개의 factor score와 PHQ-9의 총합의 상관관계를 분석해 본다.\n\ngg1 %&gt;% select(no_2, dep_score, grep('RC', colnames(.))) %&gt;%\n        dplyr::rename(ID = no_2) %&gt;% drop_na() %&gt;%\n        gather (key = factor, value=score, RC1:RC5) %&gt;%\n        filter (score &lt; 2.5 & score &gt;-2.5) %&gt;%\n        ggplot (aes(x = score, y =dep_score, group=factor)) +\n        geom_point (aes(color = factor), alpha=0.05)+\n        geom_smooth(aes(color = factor), method='lm', se=F) +\n        facet_wrap (factor ~.) +\n        theme_minimal ()\n\n\n\n\n\n\n\n\n\n\n6.4.3 요인별 사용 방법\nR1은 양의 상관관계, RC2는 음의 상관관계, RC3는 특이 사항 없고, RC4, RC5는 양의 상관관계가 있다. 각 항목별로 기울기 등 관련성의 특성이 다르므로 각각 사용하는 것이 좋겠다. 모두 합산하기 보다는 각 요인별로 설문지의 값을 더하고 이것을 이용하자는 것이다. R1은 주로 감정의 소진, R2는 감정노동 보호체계 이런 식으로 나타낼 수 있다. 연구자가 의도에 맞게 명명을 하면 된다.\n\n\n6.4.4 과제: 소진 증후군과 감정노동\n\n소진 증후군의 설문문항 5개를 더하여 총점인 burn_out_score라는 변수를 구하시오.\nburn_out_score 와 각 factor 요인간의 선형 상관관계를 그림으로 그리시오.\nregression coefficient의 절대값이 가장 큰 것 요인은?\n각 factor 요인을 따로 사용하는 것이 좋을지 같이 합산해서 같이 사용하는 것이 좋을지 의견을 내시요.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>job stress questionnaires</span>"
    ]
  },
  {
    "objectID": "Jobstress.html#mediation",
    "href": "Jobstress.html#mediation",
    "title": "6  job stress questionnaires",
    "section": "6.5 Indirect effect",
    "text": "6.5 Indirect effect\n본 강의에서는 2014년 장세진 등이 연구한 한국형 감정노동 설문지의 연구 계발 중 감정노동 설문지 하부 구조 구성에 대한 내용이다. 감정근로자를 대상으로한 질적 면담을 통해 총 26개 질적 항목이 도출되었다. 이를 조사 문항으로 변경하였고, 2014년 약 2000명의 고객 응대 근로자를 조사하였다. 이 중 변수를 축소할 수 있으지, 불필요한 변수가 있는지, 변수 사이에 일정한 특성이 있어 하부 구조를 만들수 있는지 여부를 판단하는 것이 실습 목표이다. 요인분석 이전까지의 Data step은 저번 강의를 참조하고, 이번 강의에서는 Data step에서 필요한 부분만 시행하겠다.\n필요한 library를 불러오자\n\nlibrary(diagram)\nlibrary(mediation)\n\n\ndata &lt;- c(0, \"'path B'\", 0,\n          0, 0, 0, \n          \"'path C'\", \"'path A'\", 0)\nM&lt;- matrix (nrow=3, ncol=3, byrow = TRUE, data=data)\nplot&lt;- plotmat (M, pos=c(1,2), \n                name= c( \"burnout\",\"Engaging \\nout of control\", \"Depression\"), \n                box.type = \"rect\", box.size = 0.12, box.prop=0.5,  curve=0)\n\n\n\n\n\n\n\n\n\n6.5.0.1 첫번째 testing total effect\n\ngg1 &lt;-gg1 %&gt;%\n  mutate(burnout = e1+e2+e3+e4+e5) %&gt;%\n  filter(!is.na(burnout), !is.na(dep_score), !is.na(RC3))\n\npath A 의 회귀 분석 수행하고\n\\[ Depression = b_{0} + b_{1}RC1 + e \\]\n\nfit.T &lt;- \n  gg1 %&gt;%\n  lm (data=., \n      dep_score ~ RC5)\nsummary(fit.T)$coeff %&gt;% kable()\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n7.597578\n0.1291604\n58.82283\n0\n\n\nRC5\n0.877671\n0.1307459\n6.71280\n0\n\n\n\n\n\n\n\n\n\n6.5.0.2 두번째 (mediator on X)\n두번째는 어려운 고객을 상대하는 것인 매개변수로 여겨지는 소진을 어떻게 설명하는지 분석하는 것이다.\n\\[ Burnout = b_{0} + b_{2}RC1 + e \\]\n\nfit.M &lt;- \n  gg1 %&gt;%\n  lm (data=., \n      burnout ~ RC5)\nsummary(fit.M)$coeff %&gt;% kable()  \n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n14.2992138\n0.0927035\n154.246717\n0\n\n\nRC5\n0.7289394\n0.0938415\n7.767772\n0\n\n\n\n\n\n\n\n\n\n6.5.0.3 세번째 (Y on X and Mediator)\n\\[ Depression = b_{0} + b_{3} Burnout +b_{4} RC1 + e \\]\n\nfit.Y &lt;- \n  gg1 %&gt;%\n  lm (data=., \n      dep_score ~ burnout + RC5)\nsummary(fit.Y)$coeff %&gt;% kable()\n\n\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n-5.2686545\n0.3585568\n-14.694057\n0.0000000\n\n\nburnout\n0.8997860\n0.0241078\n37.323484\n0.0000000\n\n\nRC5\n0.2217815\n0.1013842\n2.187534\n0.0288221\n\n\n\n\n\n\n\n\n\n6.5.0.4 Causal Mediation analysis\nmediation페키지의 mediate는 ACE, average causal mediaton effects와 ADE, a direct effect 를 계산하고 그 값이 0이 아닌지의 귀무가설을 bootstrapping 방법으로 계산해 준다. 본 실습에서는 상기 방법에 대한 자세한 내용은 생략하며, 실습을 중심으로 진행한다.\n\nexp &lt;- \n  mediate(fit.M, \n          fit.Y, \n          treat    =   'RC5', # 독립변수\n          mediator =   'burnout', # 매개변수\n          boot     = TRUE, \n          sims     = 500)\nsummary(exp)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value    \nACME             0.6559       0.4700         0.86  &lt;2e-16 ***\nADE              0.2218       0.0309         0.41   0.032 *  \nTotal Effect     0.8777       0.6337         1.11  &lt;2e-16 ***\nProp. Mediated   0.7473       0.5749         0.96  &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 1950 \n\n\nSimulations: 500 \n\n\n앞서 분석한 결과에서 b1 = 0.8776, p &lt;0.001, b2 = 0.7289, p &lt;0.001, b3 = 0.90, p &lt;0.001, b4 = 0.22, p = 0.03를 기억하자. 지금 분석한 결과에서 Total Effect 0.8777 은 b1으로 어려운 고객 상대가 우울에 미치는 회귀계수이다. ADE 0.22는 b4로 3번째 모델에서 소진과 어려운 고객상대가 모형에 동시에 존재할 때 우울에 대한 감정노동 요인의 회기계수이다. 이것을 direct effect로 부른다. Total Effect에서 direct effect를 뺀 값은 0.66이고 이 값이 ACME가 된다. 해석에서 가장 중요한 부분은 b1에서 b4를 뺀 부분이 ACME라는 것이다. 또한 0.88에서 0.22로 0.66 만큼 줄었고 그 값에 대한 p value 가 0.05보다 작다는 것이다. 즉 번아웃의 매개효과의 크기가 크고 통계적으로 유의한 수준으로 존재한다.\n\n\n6.5.0.5 소결\n설문지를 개발하여 나타나는 요인들을 사용할 때 주의할 점 중 하나가 매개효과에 관한 것이다. 우리가 예상했던 설문지안에는 여러 요소가 들어 있고 어떤 요소는 스트레스의 원인/반응/매개 중에 하나에 특화된 것이 있다. 예를 들어 원인은 가끔 조직적/사회적인 것을 조사하며, 반응은 매우 생물학적인 것을 대변한다. 따라서 원인과 반응간에 매개변수가 필요할 수 가 있다. 상기 매개변수를 찾는 다면, 스트레스 원인이 건강영향을 일으키는데 중재할 수 있는 지식을 발굴해 낼 수 있다.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>job stress questionnaires</span>"
    ]
  },
  {
    "objectID": "Interraction_1.html",
    "href": "Interraction_1.html",
    "title": "7  상호작용",
    "section": "",
    "text": "7.1 서론\n이 강의록은 VanderWeele와 Knol의 논문 “A Tutorial on Interaction” (Epidemiol. Methods 2014; 3(1): 33-72)을 기반으로 작성되었습니다. 상호작용(interaction)은 한 노출(exposure)의 효과가 다른 노출의 존재 여부에 따라 달라지는 현상을 의미합니다. 이 현상은 역학, 생물의학, 사회과학 등 다양한 분야에서 중요한 연구 주제입니다. 본 강의록에서는 상호작용의 개념, 동기, 척도별 분석 방법, 통계 모델, 그리고 실제 적용 사례를 다룹니다.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>상호작용</span>"
    ]
  },
  {
    "objectID": "Interraction_1.html#서론",
    "href": "Interraction_1.html#서론",
    "title": "7  상호작용",
    "section": "",
    "text": "7.1.1 주요 목표\n\n상호작용의 정의와 중요성을 이해한다.\n가법(additive) 및 승법(multiplicative) 척도에서의 상호작용 분석 방법을 학습한다.\n통계 모델을 활용한 상호작용 추정 방법을 익힌다.\n공중보건적 관점에서 상호작용의 해석을 이해한다.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>상호작용</span>"
    ]
  },
  {
    "objectID": "Interraction_1.html#상호작용이란",
    "href": "Interraction_1.html#상호작용이란",
    "title": "7  상호작용",
    "section": "7.2 상호작용이란?",
    "text": "7.2 상호작용이란?\n상호작용은 두 노출(\\(G\\), \\(E\\))이 결과(\\(D\\))에 미치는 효과가 서로 독립적이지 않고, 한 노출의 효과가 다른 노출의 수준에 따라 달라지는 경우를 말합니다. 예를 들어, 흡연과 석면 노출이 폐암 위험에 미치는 영향은 두 요인이 함께 존재할 때 더욱 크게 나타날 수 있습니다.\n\n7.2.1 상호작용의 동기\n상호작용 연구는 여러 이유로 중요합니다: 1. 자원 할당 최적화: 제한된 자원으로 특정 집단에 개입할 때, 효과가 큰 하위집단을 식별할 수 있다. 2. 기전 이해: 상호작용은 결과 발생 메커니즘에 대한 통찰을 제공할 수 있다. 3. 검정력 향상: 상호작용을 고려하면 전체 효과를 탐지하는 검정력이 높아질 수 있다. 4. 부작용 방지: 특정 집단에서 개입이 해로울 수 있는 경우를 식별한다.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>상호작용</span>"
    ]
  },
  {
    "objectID": "Interraction_1.html#상호작용의-척도",
    "href": "Interraction_1.html#상호작용의-척도",
    "title": "7  상호작용",
    "section": "7.3 상호작용의 척도",
    "text": "7.3 상호작용의 척도\n상호작용은 가법 척도와 승법 척도에서 다르게 정의됩니다. 두 이진 노출(\\(G\\), \\(E\\))과 이진 결과(\\(D\\))를 기준으로 설명합니다. 여기서 \\(p_{ge} = P(D=1 \\mid G=g, E=e)\\)는 \\(G=g\\), \\(E=e\\)일 때 결과가 발생할 확률입니다.\n\n7.3.1 가법 상호작용\n가법 상호작용은 두 노출의 공동 효과가 각 노출의 개별 효과의 합을 초과하는지를 평가합니다. 수식은 다음과 같습니다:\n\\[p_{11} - p_{10} - p_{01} + p_{00}\\]\n\n양의 가법 상호작용: 위 값이 0보다 크면 “super-additive”라 부릅니다.\n음의 가법 상호작용: 0보다 작으면 “sub-additive”라 부릅니다.\n\n예시: 흡연과 석면 노출\nHilt et al. (1986)의 데이터를 사용하여 계산해 보겠습니다.\n\n\n\n\n석면 없음\n석면 있음\n\n\n\n\n비흡연자\n0.0011\n0.0067\n\n\n흡연자\n0.0095\n0.0450\n\n\n\n가법 상호작용 계산:\n\\[ p\\_{11} - p\\_{10} - p\\_{01} + p\\_{00} = 0.0450 - 0.0095 - 0.0067 + 0.0011 = 0.0299 \\]\n결과는 양의 가법 상호작용을 나타냅니다.\n\n\n7.3.2 승법 상호작용\n승법 상호작용은 위험비(risk ratio, RR) 또는 오즈비(odds ratio, OR)를 기준으로 두 노출의 공동 효과가 각 노출의 개별 효과의 곱을 초과하는지를 평가합니다. 위험비 기준 수식은 다음과 같습니다:\n\\[ \\frac{RR_{11}}{RR_{10} \\cdot RR_{01}} = \\frac{p_{11} \\cdot p_{00}}{p_{10} \\cdot p_{01}} \\]\n\n양의 승법 상호작용: 위 값이 1보다 크면 양의 상호작용입니다.\n음의 승법 상호작용: 1보다 작으면 음의 상호작용입니다.\n\n위 예시 데이터를 사용하여 승법 상호작용을 계산:\n\\[ RR\\_{11} = \\frac{0.0450}{0.0011}, \\quad RR\\_{10} = \\frac{0.0095}{0.0011}, \\quad RR\\_{01} = \\frac{0.0067}{0.0011} \\]\n\\[ \\frac{RR_{11}}{RR_{10} \\cdot RR_{01}} = \\frac{40.9}{8.6 \\times 6.1} = 0.78 \\]\n결과는 음의 승법 상호작용을 나타냅니다.\n\n\n7.3.3 가법 vs 승법: 공중보건적 관점\n\n가법 상호작용은 공중보건적 의사결정에 더 적합합니다. 예를 들어, 자원이 제한적일 때 가법 상호작용이 양이면 특정 하위집단(\\(G=1\\))에 개입하는 것이 더 큰 효과를 가져옵니다.\n승법 상호작용은 통계적 모델링(특히 로지스틱 회귀)에서 편리하지만, 기준 위험(baseline risk)의 차이로 인해 잘못된 하위집단을 선택할 수 있습니다.\n\n\n\n\n7.3.4 가법 상호작용 추정: RERI와 통계적 모델\n가법 상호작용은 직접적인 위험 차이(\\(p_{11} - p_{10} - p_{01} + p_{00}\\))를 계산하기 어려운 경우, 상대초과위험(Relative Excess Risk due to Interaction, RERI)을 사용하여 추정합니다. RERI는 위험비 또는 오즈비를 기반으로 정의됩니다:\n\\[\nRERI_{RR} = RR_{11} - RR_{10} - RR_{01} + 1\n\\]\n로지스틱 회귀를 사용할 경우, 오즈비 기반 RERI는 다음과 같이 계산됩니다:\n\\[\nRERI_{OR} = e^{\\gamma_1 + \\gamma_2 + \\gamma_3} - e^{\\gamma_1} - e^{\\gamma_2} + 1\n\\]\n여기서 \\(\\gamma_1\\), \\(\\gamma_2\\), \\(\\gamma_3\\)는 로지스틱 회귀 모델의 계수입니다:\n\\[\n\\log \\text{it} \\{ P(D=1 \\mid G=g, E=e, C=c) \\} = \\gamma_0 + \\gamma_1 g + \\gamma_2 e + \\gamma_3 eg + \\gamma_4' c\n\\]\n\n장점: 로지스틱 회귀는 연속형 공변량(\\(C\\))이 포함된 경우에도 수렴 문제가 적으며, 사례-대조 연구(case-control study)에서도 사용 가능합니다.\n주의점: 결과가 흔한 경우(\\(&gt;10\\%\\)), \\(RERI_{OR}\\)은 \\(RERI_{RR}\\)을 정확히 근사하지 못할 수 있습니다. 이 경우 로그선형 모델이나 수정된 포아송 회귀를 고려할 수 있습니다.\n\n\n7.3.4.1 RERI의 공중보건적 해석\n\n\\(RERI &gt; 0\\): \\(G=1\\) 집단에서 \\(E\\)에 대한 개입이 더 큰 공중보건적 효과를 가짐.\n\\(RERI &lt; 0\\): \\(G=0\\) 집단에서 \\(E\\)에 대한 개입이 더 효과적.\n\\(RERI = 0\\): 두 집단 간 개입 효과 차이 없음.\n\n\n\n\n7.3.5 연속형 및 범주형 노출에서의 상호작용\n\n7.3.5.1 연속형 노출\n연속형 노출(\\(G\\), \\(E\\))의 경우, RERI는 특정 수준 간 변화(예: \\(G\\)가 \\(g_0\\)에서 \\(g_1\\)로, \\(E\\)가 \\(e_0\\)에서 \\(e_1\\)로)를 기준으로 계산됩니다:\n\\[\nRERI_{OR} = e^{(\\gamma_1 (g_1 - g_0) + \\gamma_2 (e_1 - e_0) + \\gamma_3 (g_1 e_1 - g_0 e_0))} - e^{(\\gamma_1 (g_1 - g_0) + \\gamma_3 (g_1 - g_0) e_0)} - e^{(\\gamma_2 (e_1 - e_0) + \\gamma_3 (e_1 - e_0) g_0)} + 1\n\\]\n주의: - RERI는 비교하는 수준(\\(g_0, g_1\\), \\(e_0, e_1\\))에 따라 달라질 수 있습니다. - 절대 위험의 가법 상호작용 크기와 RERI의 크기는 기준 위험(\\(p_{00}\\))에 따라 달라질 수 있으므로, 방향(양/음/0)만 해석하는 것이 안전합니다.\n\n\n7.3.5.2 범주형 노출\n범주형 노출의 경우, 두 수준 간 비교를 위해 데이터를 제한하여 이진 노출처럼 분석합니다. 예를 들어, 노출 \\(A\\) (수준: A1, A2, A3)와 \\(B\\) (수준: B1, B2, B3, B4)를 비교할 때, A1 vs A2와 B1 vs B4를 선택하여 분석합니다.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>상호작용</span>"
    ]
  },
  {
    "objectID": "Interraction_1.html#r을-사용한-상호작용-분석",
    "href": "Interraction_1.html#r을-사용한-상호작용-분석",
    "title": "7  상호작용",
    "section": "7.4 R을 사용한 상호작용 분석",
    "text": "7.4 R을 사용한 상호작용 분석\nR을 사용하여 가법 상호작용(RERI)을 추정하는 방법을 소개합니다. glm()으로 로지스틱 회귀를 수행하고, car 패키지의 deltaMethod()로 RERI와 신뢰구간을 계산합니다.\n\n7.4.1 R 코드: 이진 노출에 대한 가법 상호작용\n다음은 이진 노출(\\(G\\), \\(E\\))에 대한 RERI 추정 코드입니다. 데이터프레임 mydata에 결과 변수 d, 노출 변수 g, e, 공변량 c1, c2, c3가 포함되어 있다고 가정합니다.\n\n# 패키지 로드\nlibrary(car)\nlibrary(dplyr)\n\n\n# 데이터 시뮬레이션\nset.seed(123) # 결과 재현을 위해 시드 설정\nN_binary &lt;- 1000 # 샘플 크기\n\n# 공변량 생성\nc1_bin &lt;- rnorm(N_binary, 50, 10) # 예: 나이\nc2_bin &lt;- rbinom(N_binary, 1, 0.4) # 예: 성별 (0 또는 1)\nc3_bin &lt;- rnorm(N_binary, 25, 5)  # 예: BMI\n#c1_bin\n# 이진 노출 G와 E 생성 (서로 약간의 상관관계가 있을 수 있도록 시뮬레이션)\ng_bin_latent &lt;- rnorm(N_binary)\ne_bin_latent &lt;- 0.3 * g_bin_latent + rnorm(N_binary) # g와 e 간 약한 상관관계 부여\ng_bin &lt;- ifelse(g_bin_latent &gt; median(g_bin_latent), 1, 0) # 이진화\ne_bin &lt;- ifelse(e_bin_latent &gt; median(e_bin_latent), 1, 0) # 이진화\n\n# 결과 변수 d 생성 (로지스틱 모델 기반)\n# logit(P(d=1)) = beta0 + beta_g*g + beta_e*e + beta_ge*g*e + beta_c1*c1 + beta_c2*c2 ...\n# RERI_OR = exp(beta_g + beta_e + beta_ge) - exp(beta_g) - exp(beta_e) + 1\n# 목표 RERI_OR = 0.5 (예시)\n# exp(beta_g)=1.5, exp(beta_e)=1.2 이면,\n# exp(beta_g + beta_e + beta_ge) = 0.5 + 1.5 + 1.2 - 1 = 2.2\n# beta_g = log(1.5) approx 0.405\n# beta_e = log(1.2) approx 0.182\n# beta_ge = log(2.2) - log(1.5) - log(1.2) = log(2.2 / (1.5 * 1.2)) = log(2.2/1.8) = log(1.222) approx 0.200\n\nlog_odds_bin &lt;- -3 + 0.405*g_bin + 0.182*e_bin + 0.200*g_bin*e_bin + 0.02*c1_bin - 0.1*c2_bin + 0.01*c3_bin\nprob_d_bin &lt;- plogis(log_odds_bin) # plogis는 1/(1+exp(-x))와 동일 (로지스틱 함수)\nd_bin &lt;- rbinom(N_binary, 1, prob_d_bin)\n\nmydata_binary &lt;- data.frame(d = d_bin, g = g_bin, e = e_bin, c1 = c1_bin, c2 = c2_bin, c3 = c3_bin)\n\n# 로지스틱 회귀 모델 적합\n# d ~ g + e + g*e + c1 + c2 + c3 (g*e가 g:e와 동일)\n# 주의: 모델 계수의 순서가 parameterNames와 일치해야 함.\n# (Intercept), g, e, c1, c2, c3, g:e 순으로 나오는 경향이 있음.\n# 명시적으로 순서를 맞추려면 g + e + c1 + c2 + c3 + g:e 와 같이 인터랙션 항을 뒤로.\n# 또는 parameterNames를 names(coef(model_binary))로 하고, 수식에서 실제 변수명 사용.\n# 여기서는 사용자님의 parameterNames 방식(\"b0\"...\"b6\")을 따르기 위해,\n# g:e 항이 4번째 예측변수(b3)가 되도록 모델 정의.\nmodel_binary &lt;- glm(d ~ g + e + g:e + c1 + c2 + c3,\n                    family = binomial(link = \"logit\"), data = mydata_binary)\nprint(\"Binary Model Summary:\")\nprint(summary(model_binary))\n\n# RERI_OR 계산 (deltaMethod 사용)\n# parameterNames 순서: (Intercept), g, e, g:e, c1, c2, c3\n# 따라서 b0=(Intercept), b1=g, b2=e, b3=g:e, b4=c1, b5=c2, b6=c3\n# deltaMethod에서 사용하는 b1,b2,b3는 G, E, G:E의 계수를 의미함.\n# names(coef(model_binary))를 확인하여 b1,b2,b3가 어떤 계수인지 정확히 파악해야함.\n# 만약 g, e, g:e가 모델에서 2, 3, 7번째 계수라면 (Intercept 포함)\n# parameterNames = names(coef(model_binary))로 하고, 수식에서 실제 변수명을 사용하는 것이 더 안전.\n# 그러나 사용자님 코드의 parameterNames 방식(b0, b1...)을 따름.\n# 이 경우 g, e, g:e가 각각 b1, b2, b3에 해당함 (Intercept가 b0).\nparam_names_bin &lt;- paste0(\"b\", 0:(length(coef(model_binary))-1))\n\ncat(\"\\nBinary Model RERI_OR Calculation:\\n\")\nreri_binary &lt;- tryCatch({\n  deltaMethod(model_binary,\n              \"exp(b1 + b2 + b3) - exp(b1) - exp(b2) + 1\",\n              parameterNames = param_names_bin)\n}, error = function(e) {\n  cat(\"Error in deltaMethod for binary model: \", conditionMessage(e), \"\\n\")\n  cat(\"Check coefficient names and parameterNames argument.\\n\")\n  cat(\"Coefficients from model: \", paste(names(coef(model_binary)), collapse=\", \"), \"\\n\")\n  cat(\"Expected parameterNames: \", paste(param_names_bin, collapse=\", \"), \"\\n\")\n  return(NULL)\n})\nif (!is.null(reri_binary)) {\n  print(reri_binary)\n}\n\n\n\n7.4.2 R 코드: 연속형 노출에 대한 가법 상호작용\n연속형 노출의 경우, 비교 수준(예: \\(G\\)가 0에서 2로, \\(E\\)가 5에서 25로)을 지정하여 RERI를 계산합니다.\n\n# 데이터 시뮬레이션\nset.seed(456)\nN_continuous &lt;- 1000\n\nc1_cont &lt;- rnorm(N_continuous, 50, 10)\nc2_cont &lt;- rbinom(N_continuous, 1, 0.4)\nc3_cont &lt;- rnorm(N_continuous, 25, 5)\n\n# 연속형 노출 G와 E 생성\ng_cont &lt;- rnorm(N_continuous, 10, 2) # 예: 노출 농도\ne_cont &lt;- rnorm(N_continuous, 20, 5) # 예: 노출 기간\n\n# 결과 변수 d 생성 (연속형 노출을 사용한 로지스틱 모델 기반)\n# logit(P(d=1)) = beta0 + beta_g*g + beta_e*e + beta_ge*g*e + ...\nlog_odds_cont &lt;- -5 + 0.05*g_cont + 0.02*e_cont + 0.001*g_cont*e_cont + 0.03*c1_cont - 0.2*c2_cont + 0.01*c3_cont\nprob_d_cont &lt;- plogis(log_odds_cont)\nd_cont &lt;- rbinom(N_continuous, 1, prob_d_cont)\n\nmydata_continuous &lt;- data.frame(d = d_cont, g = g_cont, e = e_cont,\n                                c1 = c1_cont, c2 = c2_cont, c3 = c3_cont)\n\n# 비교 수준 지정\ng0 &lt;- 5; g1 &lt;- 15  # g가 5에서 15로 변할 때\ne0 &lt;- 10; e1 &lt;- 30 # e가 10에서 30으로 변할 때\n\n# 로지스틱 회귀 모델 적합\nmodel_continuous &lt;- glm(d ~ g + e + g:e + c1 + c2 + c3,\n                        family = binomial(link = \"logit\"), data = mydata_continuous)\nprint(\"Continuous Model Summary:\")\n\n[1] \"Continuous Model Summary:\"\n\nprint(summary(model_continuous))\n\n\nCall:\nglm(formula = d ~ g + e + g:e + c1 + c2 + c3, family = binomial(link = \"logit\"), \n    data = mydata_continuous)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept) -7.736915   2.486636  -3.111  0.00186 **\ng            0.247759   0.224382   1.104  0.26951   \ne            0.145378   0.109010   1.334  0.18233   \nc1           0.028906   0.010434   2.770  0.00560 **\nc2          -0.164807   0.207894  -0.793  0.42793   \nc3           0.012149   0.020841   0.583  0.55993   \ng:e         -0.007472   0.010456  -0.715  0.47480   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 709.59  on 999  degrees of freedom\nResidual deviance: 686.15  on 993  degrees of freedom\nAIC: 700.15\n\nNumber of Fisher Scoring iterations: 5\n\n# RERI_OR 계산 (deltaMethod 사용)\n# 사용자님의 강의록에 있는 RERI 공식 사용\n# RERI_OR = exp(gamma1*(g1-g0) + gamma2*(e1-e0) + gamma3*(g1*e1 - g0*e0))\n#           - exp(gamma1*(g1-g0) + gamma3*(g1-g0)*e0)\n#           - exp(gamma2*(e1-e0) + gamma3*(e1-e0)*g0) + 1\n# 여기서 gamma1, gamma2, gamma3는 모델의 g, e, g:e 계수 (b1, b2, b3에 해당)\nreri_formula_cont &lt;- sprintf(\n  \"exp( b1*(%f-%f) + b2*(%f-%f) + b3*((%f*%f) - (%f*%f)) ) - exp( b1*(%f-%f) + b3*((%f-%f)*%f) ) - exp( b2*(%f-%f) + b3*((%f-%f)*%f) ) + 1\",\n  g1, g0, e1, e0, g1, e1, g0, e0,  # term for OR11\n  g1, g0, g1, g0, e0,              # term for OR10 (effect of G at E=e0)\n  e1, e0, e1, e0, g0               # term for OR01 (effect of E at G=g0)\n)\nparam_names_cont &lt;- paste0(\"b\", 0:(length(coef(model_continuous))-1))\n\ncat(\"\\nContinuous Model RERI_OR Calculation:\\n\")\n\n\nContinuous Model RERI_OR Calculation:\n\ncat(\"Formula used for deltaMethod:\\n\", reri_formula_cont, \"\\n\")\n\nFormula used for deltaMethod:\n exp( b1*(15.000000-5.000000) + b2*(30.000000-10.000000) + b3*((15.000000*30.000000) - (5.000000*10.000000)) ) - exp( b1*(15.000000-5.000000) + b3*((15.000000-5.000000)*10.000000) ) - exp( b2*(30.000000-10.000000) + b3*((30.000000-10.000000)*5.000000) ) + 1 \n\nreri_continuous &lt;- tryCatch({\n  deltaMethod(model_continuous, reri_formula_cont, parameterNames = param_names_cont)\n}, error = function(e) {\n  cat(\"Error in deltaMethod for continuous model: \", conditionMessage(e), \"\\n\")\n  cat(\"Check coefficient names and parameterNames argument.\\n\")\n  cat(\"Coefficients from model: \", paste(names(coef(model_continuous)), collapse=\", \"), \"\\n\")\n  cat(\"Expected parameterNames: \", paste(param_names_cont, collapse=\", \"), \"\\n\")\n  return(NULL)\n})\n\nError in deltaMethod for continuous model:  함수 \"deltaMethod\"를 찾을 수 없습니다 \nCheck coefficient names and parameterNames argument.\nCoefficients from model:  (Intercept), g, e, c1, c2, c3, g:e \nExpected parameterNames:  b0, b1, b2, b3, b4, b5, b6 \n\nif (!is.null(reri_continuous)) {\n  print(reri_continuous)\n}\n\n\n\n7.4.3 R 코드: 범주형 노출에 대한 가법 상호작용\n범주형 노출의 경우, 특정 수준 쌍을 선택하여 이진 노출처럼 분석합니다.\n\nlibrary(tidyverse)\n# 데이터 시뮬레이션\nset.seed(789)\nN_categorical &lt;- 1000\n\nc1_cat &lt;- rnorm(N_categorical, 50, 10)\nc2_cat &lt;- rbinom(N_categorical, 1, 0.4)\nc3_cat &lt;- rnorm(N_categorical, 25, 5)\n\n# 범주형 노출 A (3수준), B (4수준) 생성\nA_cat &lt;- factor(sample(c(\"A1\", \"A2\", \"A3\"), N_categorical, replace = TRUE, prob = c(0.4, 0.3, 0.3)))\nB_cat &lt;- factor(sample(c(\"B1\", \"B2\", \"B3\", \"B4\"), N_categorical, replace = TRUE, prob = c(0.25, 0.25, 0.25, 0.25)))\n\n# 결과 변수 d 생성\n# A1&B1을 참조로 가정.\n# A2 vs A1, A3 vs A1 효과, B2 vs B1, B3 vs B1, B4 vs B1 효과\n# A2&B2 에서의 상호작용 등...\n# 단순화를 위해, A와 B의 특정 조합에 따라 확률 부여\nlog_odds_cat &lt;- -2.5 +\n  ifelse(A_cat == \"A2\", 0.5, ifelse(A_cat == \"A3\", 0.8, 0)) + # A 주효과 (A1 대비)\n  ifelse(B_cat == \"B2\", 0.3, ifelse(B_cat == \"B3\", 0.6, ifelse(B_cat == \"B4\", 0.9, 0))) + # B 주효과 (B1 대비)\n  ifelse(A_cat == \"A2\" & B_cat == \"B4\", 0.7, 0) + # A2와 B4 간의 상호작용 (예시)\n  0.01*c1_cat - 0.15*c2_cat + 0.005*c3_cat\n\nprob_d_cat &lt;- plogis(log_odds_cat)\nd_cat &lt;- rbinom(N_categorical, 1, prob_d_cat)\n\nmydata_categorical_full &lt;- data.frame(d = d_cat, A = A_cat, B = B_cat,\n                                      c1 = c1_cat, c2 = c2_cat, c3 = c3_cat)\n\n# 분석: A1 vs A2 (A1이 참조), B1 vs B4 (B1이 참조) 간의 상호작용\nmydata_subset &lt;- mydata_categorical_full %&gt;%\n  filter(A %in% c(\"A1\", \"A2\") & B %in% c(\"B1\", \"B4\")) %&gt;%\n  mutate(\n    g = ifelse(A == \"A2\", 1, 0), # A1 (ref=0) vs A2 (exp=1)\n    e = ifelse(B == \"B4\", 1, 0)  # B1 (ref=0) vs B4 (exp=1)\n  )\n\n# 로지스틱 회귀 모델 적합 (부분집합 사용)\nmodel_categorical_subset &lt;- glm(d ~ g + e + g:e + c1 + c2 + c3,\n                                family = binomial(link = \"logit\"), data = mydata_subset)\nprint(\"Categorical (Subset) Model Summary:\")\n\n[1] \"Categorical (Subset) Model Summary:\"\n\nprint(summary(model_categorical_subset))\n\n\nCall:\nglm(formula = d ~ g + e + g:e + c1 + c2 + c3, family = binomial(link = \"logit\"), \n    data = mydata_subset)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept) -3.21280    1.00167  -3.207  0.00134 **\ng            0.30290    0.38467   0.787  0.43102   \ne            0.50806    0.37314   1.362  0.17333   \nc1           0.01736    0.01300   1.335  0.18173   \nc2           0.03761    0.27245   0.138  0.89022   \nc3           0.02237    0.02685   0.833  0.40481   \ng:e          1.67984    0.53494   3.140  0.00169 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 413.78  on 353  degrees of freedom\nResidual deviance: 355.37  on 347  degrees of freedom\nAIC: 369.37\n\nNumber of Fisher Scoring iterations: 4\n\n# RERI_OR 계산 (deltaMethod 사용 - 이진 노출과 동일한 방식)\nparam_names_cat_subset &lt;- paste0(\"b\", 0:(length(coef(model_categorical_subset))-1))\n\ncat(\"\\nCategorical (Subset) Model RERI_OR Calculation:\\n\")\n\n\nCategorical (Subset) Model RERI_OR Calculation:\n\nreri_categorical_subset &lt;- tryCatch({\n  deltaMethod(model_categorical_subset,\n              \"exp(b1 + b2 + b3) - exp(b1) - exp(b2) + 1\",\n              parameterNames = param_names_cat_subset)\n}, error = function(e) {\n  cat(\"Error in deltaMethod for categorical (subset) model: \", conditionMessage(e), \"\\n\")\n  cat(\"Check coefficient names and parameterNames argument.\\n\")\n  cat(\"Coefficients from model: \", paste(names(coef(model_categorical_subset)), collapse=\", \"), \"\\n\")\n  cat(\"Expected parameterNames: \", paste(param_names_cat_subset, collapse=\", \"), \"\\n\")\n  return(NULL)\n})\n\nError in deltaMethod for categorical (subset) model:  함수 \"deltaMethod\"를 찾을 수 없습니다 \nCheck coefficient names and parameterNames argument.\nCoefficients from model:  (Intercept), g, e, c1, c2, c3, g:e \nExpected parameterNames:  b0, b1, b2, b3, b4, b5, b6 \n\nif (!is.null(reri_categorical_subset)) {\n  print(reri_categorical_subset)\n}\n\n# RERI와 신뢰구간 계산을 위한 대안: `interactionR` 패키지\n# `interactionR` 패키지는 로지스틱 회귀 모델 객체를 직접 사용하여 RERI(ICR로 표시), AP 등 다양한\n# 상호작용 척도와 그 신뢰구간을 계산해 줄 수 있습니다.\n# 사용법 예시:\n# model_for_ir &lt;- glm(d ~ g_bin + e_bin + g_bin:e_bin + c1 + c2 + c3,\n#                     data = mydata_binary, family = binomial)\n# interaction_measures_result &lt;- interactionR::interaction.ratios(model_for_ir)\n# print(interaction_measures_result)\n# 이 패키지는 특히 신뢰구간 계산에 유용합니다.\n# deltaMethod를 직접 사용하는 것보다 복잡한 수식 없이 결과를 얻을 수 있습니다.\n# 단, exposure_names 등의 인자를 모델에 맞게 정확히 지정해야 합니다.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>상호작용</span>"
    ]
  },
  {
    "objectID": "Interraction_1.html#결론",
    "href": "Interraction_1.html#결론",
    "title": "7  상호작용",
    "section": "7.5 결론",
    "text": "7.5 결론\n상호작용 분석은 역학 연구에서 공중보건적 의사결정과 기전 이해에 필수적입니다. 가법 상호작용(RERI)은 자원 할당 최적화에 유용하며, 승법 상호작용은 로지스틱 회귀를 통한 통계적 분석에 적합합니다. R을 사용한 실습 코드는 이진, 연속형, 범주형 노출에 대한 RERI 추정을 지원하며, car 패키지의 deltaMethod()를 활용해 신뢰구간을 계산합니다. 두 척도를 함께 보고하여 종합적인 해석을 제공하는 것이 권장됩니다.\n\n7.5.1 참고문헌\n\nVanderWeele, T. J., & Knol, M. J. (2014). A Tutorial on Interaction. Epidemiologic Methods, 3(1), 33-72.\nRothman, K. J. (1986). Modern Epidemiology. Boston, MA: Little, Brown and Company.\nGreenland, S., Lash, T. L., & Rothman, K. J. (2008). Modern Epidemiology. Philadelphia, PA: Lippincott Williams and Wilkins.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>상호작용</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "8  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "직업환경연구방법",
    "section": "",
    "text": "소개\n직업병 역학조사 연구에 필요한 방법론을 저장하는 곳입니다.\njinha@dspubs.org",
    "crumbs": [
      "소개"
    ]
  }
]